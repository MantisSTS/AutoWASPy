[
  {
    "id": "MASTG-TEST-0017",
    "title": "Mobile Security Test 0017",
    "category": "Android Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\nMake sure that the unlocked key is used during the application flow. For example, the key may be used to decrypt local storage or a message received from a remote endpoint. If the application simply checks whether the user has unlocked the key or not, the application may be vulnerable to a local authentication bypass."
  },
  {
    "id": "MASTG-TEST-0018",
    "title": "Mobile Security Test 0018",
    "category": "Android Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\nNote that there are quite some vendor/third party SDKs, which provide biometric support, but which have their own insecurities. Be very cautious when using third party SDKs to handle sensitive authentication logic."
  },
  {
    "id": "MASTG-TEST-0002",
    "title": "Mobile Security Test 0002",
    "category": "Android Security Testing",
    "description": "For any publicly accessible data storage, any process can override the data. This means that input validation needs to be applied the moment the data is read back again.",
    "full_description": "For any publicly accessible data storage, any process can override the data. This means that input validation needs to be applied the moment the data is read back again.\n\n> Note: The same is true for private accessible data on a rooted device"
  },
  {
    "id": "MASTG-TEST-0025",
    "title": "content query --uri content://sg.vp.owasp_mobile.provider.College/students",
    "category": "Android Security Testing",
    "description": "To test for [injection flaws](../../../Document/0x04h-Testing-Code-Quality.md#injection-flaws \"Injection Flaws\") you need to first rely on other tests and check for functionality that might have been ...",
    "full_description": "To test for [injection flaws](../../../Document/0x04h-Testing-Code-Quality.md#injection-flaws \"Injection Flaws\") you need to first rely on other tests and check for functionality that might have been exposed:\n\n- @MASTG-TEST-0028\n- @MASTG-TEST-0029\n- @MASTG-TEST-0035"
  },
  {
    "id": "MASTG-TEST-0026",
    "title": "Mobile Security Test 0026",
    "category": "Android Security Testing",
    "description": "When testing for [implicit intents](../../../Document/0x05h-Testing-Platform-Interaction.md#implicit-intents) you need to check if they are vulnerable to injection attacks or potentially leaking sensi...",
    "full_description": "When testing for [implicit intents](../../../Document/0x05h-Testing-Platform-Interaction.md#implicit-intents) you need to check if they are vulnerable to injection attacks or potentially leaking sensitive data."
  },
  {
    "id": "MASTG-TEST-0027",
    "title": "Mobile Security Test 0027",
    "category": "Android Security Testing",
    "description": "In order to test for [URL loading in WebViews](../../../Document/0x05h-Testing-Platform-Interaction.md#url-loading-in-webviews \"URL Loading in WebViews\") you need to carefully analyze [handling page n...",
    "full_description": "In order to test for [URL loading in WebViews](../../../Document/0x05h-Testing-Platform-Interaction.md#url-loading-in-webviews \"URL Loading in WebViews\") you need to carefully analyze [handling page navigation](https://developer.android.com/guide/webapps/webview#HandlingNavigation \"Handling page navigation\"), especially when users might be able to navigate away from a trusted environment. The default and safest behavior on Android is to let the default web browser open any link that the user might click inside the WebView. However, this default logic can be modified by configuring a `WebViewClient` which allows navigation requests to be handled by the app itself."
  },
  {
    "id": "MASTG-TEST-0034",
    "title": "Mobile Security Test 0034",
    "category": "Android Security Testing",
    "description": "To test for [object persistence](../../../Document/0x05h-Testing-Platform-Interaction.md#object-persistence \"Object Persistence\") being used for storing sensitive information on the device, first iden...",
    "full_description": "To test for [object persistence](../../../Document/0x05h-Testing-Platform-Interaction.md#object-persistence \"Object Persistence\") being used for storing sensitive information on the device, first identify all instances of object serialization and check if they carry any sensitive data. If yes, check if it is properly protected against eavesdropping or unauthorized modification.\n\nThere are a few generic remediation steps that you can always take:\n\n1. Make sure that sensitive data has been encrypted and HMACed/signed after serialization/persistence. Evaluate the signature or HMAC before you use the data. See the chapter \"[Android Cryptographic APIs](../../../Document/0x05e-Testing-Cryptography.md)\" for more details.\n2. Make sure that the keys used in step 1 can't be extracted easily. The user and/or application instance should be properly authenticated/authorized to obtain the keys. See the chapter \"[Data Storage on Android](../../../Document/0x05d-Testing-Data-Storage.md)\" for more details.\n3. Make sure that the data within the de-serialized object is carefully validated before it is actively used (e.g., no exploit of business/application logic).\n\nFor high-risk applications that focus on availability, we recommend that you use `Serializable` only when the serialized classes are stable. Second, we recommend not using reflection-based persistence because\n\n- the attacker could find the method's signature via the String-based argument\n- the attacker might be able to manipulate the reflection-based steps to execute business logic."
  },
  {
    "id": "MASTG-TEST-0036",
    "title": "Mobile Security Test 0036",
    "category": "Android Security Testing",
    "description": "To test for [enforced updating](../../../Document/0x05h-Testing-Platform-Interaction.md#enforced-updating \"Enforced Updating\") you need to check if the app has support for in-app updates and validate ...",
    "full_description": "To test for [enforced updating](../../../Document/0x05h-Testing-Platform-Interaction.md#enforced-updating \"Enforced Updating\") you need to check if the app has support for in-app updates and validate if it's properly enforced so that the user is not able to continue using the app without updating it first."
  },
  {
    "id": "MASTG-TEST-0042",
    "title": "Mobile Security Test 0042",
    "category": "Android Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\nDetecting vulnerabilities in third party dependencies can be done by means of the OWASP Dependency checker. This is best done by using a gradle plugin, such as [`dependency-check-gradle`](https://github.com/jeremylong/dependency-check-gradle \"dependency-check-gradle\").\nIn order to use the plugin, the following steps need to be applied:\nInstall the plugin from the Maven central repository by adding the following script to your build.gradle:\n\n```default\nbuildscript {\n    repositories {\n        mavenCentral()\n    }\n    dependencies {\n        classpath 'org.owasp:dependency-check-gradle:3.2.0'\n    }\n}\n\napply plugin: 'org.owasp.dependencycheck'\n```\n\nOnce gradle has invoked the plugin, you can create a report by running:\n\n```bash\ngradle assemble\ngradle dependencyCheckAnalyze --info\n```\n\nThe report will be in `build/reports` unless otherwise configured. Use the report in order to analyze the vulnerabilities found. See remediation on what to do given the vulnerabilities found with the libraries.\n\nPlease be advised that the plugin requires to download a vulnerability feed. Consult the documentation in case issues arise with the plugin.\n\nLastly, please note that for hybrid applications, one will have to check the JavaScript dependencies with RetireJS. Similarly for Xamarin, one will have to check the C# dependencies.\n\nWhen a library is found to contain vulnerabilities, then the following reasoning applies:\n\n- Is the library packaged with the application? Then check whether the library has a version in which the vulnerability is patched. If not, check whether the vulnerability actually affects the application. If that is the case or might be the case in the future, then look for an alternative which provides similar functionality, but without the vulnerabilities.\n- Is the library not packaged with the application? See if there is a patched version in which the vulnerability is fixed. If this is not the case, check if the implications of the vulnerability for the build-process. Could the vulnerability impede a build or weaken the security of the build-pipeline? Then try looking for an alternative in which the vulnerability is fixed.\n\nWhen the sources are not available, one can decompile the app and check the JAR files. When Dexguard or @MASTG-TOOL-0022 are applied properly, then version information about the library is often obfuscated and therefore gone. Otherwise you can still find the information very often in the comments of the Java files of given libraries. Tools such as MobSF can help in analyzing the possible libraries packed with the application. If you can retrieve the version of the library, either via comments, or via specific methods used in certain versions, you can look them up for CVEs by hand.\n\nIf the application is a high-risk application, you will end up vetting the library manually. In that case, there are specific requirements for native code, which you can find in the chapter \"[Testing Code Quality](../../../Document/0x04h-Testing-Code-Quality.md)\". Next to that, it is good to vet whether all best practices for software engineering are applied."
  },
  {
    "id": "MASTG-TEST-0043",
    "title": "Mobile Security Test 0043",
    "category": "Android Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\nThere are various items to look for:\n\n- Are there native code parts? If so: check for the given issues in the general memory corruption section. Native code can easily be spotted given JNI-wrappers, .CPP/.H/.C files, NDK or other native frameworks.\n- Is there Java code or Kotlin code? Look for Serialization/deserialization issues, such as described in [A brief history of Android deserialization vulnerabilities](https://securitylab.github.com/research/android-deserialization-vulnerabilities \"android deserialization\").\n\nNote that there can be Memory leaks in Java/Kotlin code as well. Look for various items, such as: BroadcastReceivers which are not unregistered, static references to `Activity` or `View` classes, Singleton classes that have references to `Context`, Inner Class references, Anonymous Class references, AsyncTask references, Handler references, Threading done wrong, TimerTask references. For more details, please check:\n\n- [9 ways to avoid memory leaks in Android](https://android.jlelse.eu/9-ways-to-avoid-memory-leaks-in-android-b6d81648e35e \"9 ways to avoid memory leaks in Android\")\n- [Memory Leak Patterns in Android](https://android.jlelse.eu/memory-leak-patterns-in-android-4741a7fcb570 \"Memory Leak Patterns in Android\")."
  },
  {
    "id": "MASTG-TEST-0044",
    "title": "Mobile Security Test 0044",
    "category": "Android Security Testing",
    "description": "Mobile application security test as per OWASP MASTG guidelines.",
    "full_description": "Mobile application security test as per OWASP MASTG guidelines."
  },
  {
    "id": "MASTG-TEST-0013",
    "title": "Mobile Security Test 0013",
    "category": "Android Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\nIdentify all the instances of symmetric key encryption in code and look for any mechanism which loads or provides a symmetric key. You can look for:\n\n- symmetric algorithms (such as `DES`, `AES`, etc.)\n- specifications for a key generator (such as `KeyGenParameterSpec`, `KeyPairGeneratorSpec`, `KeyPairGenerator`, `KeyGenerator`, `KeyProperties`, etc.)\n- classes importing `java.security.*`, `javax.crypto.*`, `android.security.*`, `android.security.keystore.*`\n\nCheck also the [list of common cryptographic configuration issues](../../../Document/0x04g-Testing-Cryptography.md#common-configuration-issues).\n\nFor each identified instance verify if the used symmetric keys:\n\n- are not part of the application resources\n- cannot be derived from known values\n- are not hardcoded in code\n\nFor each hardcoded symmetric key, verify that is not used in security-sensitive contexts as the only method of encryption.\n\nAs an example we illustrate how to locate the use of a hardcoded encryption key. First disassemble and decompile (@MASTG-TECH-0017) the app to obtain Java code, e.g. by using @MASTG-TOOL-0018.\n\nNow search the files for the usage of the `SecretKeySpec` class, e.g. by simply recursively grepping on them or using jadx search function:\n\n```bash\ngrep -r \"SecretKeySpec\"\n```\n\nThis will return all classes using the `SecretKeySpec` class. Now examine those files and trace which variables are used to pass the key material. The figure below shows the result of performing this assessment on a production ready application. We can clearly locate the use of a static encryption key that is hardcoded and initialized in the static byte array `Encrypt.keyBytes`.\n\n<img src=\"Images/Chapters/0x5e/static_encryption_key.png\" width=\"600px\"/>"
  },
  {
    "id": "MASTG-TEST-0014",
    "title": "Mobile Security Test 0014",
    "category": "Android Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\nIdentify all the instances of the cryptographic primitives in code. Identify all custom cryptography implementations. You can look for:\n\n- classes `Cipher`, `Mac`, `MessageDigest`, `Signature`\n- interfaces `Key`, `PrivateKey`, `PublicKey`, `SecretKey`\n- functions `getInstance`, `generateKey`\n- exceptions `KeyStoreException`, `CertificateException`, `NoSuchAlgorithmException`\n- classes which uses `java.security.*`, `javax.crypto.*`, `android.security.*` and `android.security.keystore.*` packages.\n\nIdentify that all calls to getInstance use default `provider` of security services by not specifying it (it means AndroidOpenSSL aka Conscrypt). `Provider` can only be specified in `KeyStore` related code (in that situation `KeyStore` should be provided as `provider`). If other `provider` is specified it should be verified according to situation and business case (i.e. Android API version), and `provider` should be examined against potential vulnerabilities.\n\nEnsure that the best practices outlined in the \"[Cryptography for Mobile Apps](../../../Document/0x04g-Testing-Cryptography.md)\" chapter are followed. Look at [insecure and deprecated algorithms](../../../Document/0x04g-Testing-Cryptography.md#identifying-insecure-andor-deprecated-cryptographic-algorithms) and [common configuration issues](../../../Document/0x04g-Testing-Cryptography.md#common-configuration-issues)."
  },
  {
    "id": "MASTG-TEST-0015",
    "title": "Mobile Security Test 0015",
    "category": "Android Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\nIdentify all instances where cryptography is used. You can look for:\n\n- classes `Cipher`, `Mac`, `MessageDigest`, `Signature`\n- interfaces `Key`, `PrivateKey`, `PublicKey`, `SecretKey`\n- functions `getInstance`, `generateKey`\n- exceptions `KeyStoreException`, `CertificateException`, `NoSuchAlgorithmException`\n- classes importing `java.security.*`, `javax.crypto.*`, `android.security.*`, `android.security.keystore.*`\n\nFor each identified instance, identify its purpose and its type. It can be used:\n\n- for encryption/decryption - to ensure data confidentiality\n- for signing/verifying - to ensure integrity of data (as well as accountability in some cases)\n- for maintenance - to protect keys during certain sensitive operations (such as being imported to the KeyStore)\n\nAdditionally, you should identify the business logic which uses identified instances of cryptography.\n\nDuring verification the following checks should be performed:\n\n- are all keys used according to the purpose defined during its creation? (it is relevant to KeyStore keys, which can have KeyProperties defined)\n- for asymmetric keys, is the private key being exclusively used for signing and the public key encryption?\n- are symmetric keys used for multiple purposes? A new symmetric key should be generated if it's used in a different context.\n- is cryptography used according to its business purpose?"
  },
  {
    "id": "MASTG-TEST-0016",
    "title": "Mobile Security Test 0016",
    "category": "Android Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\nIdentify all the instances of random number generators and look for either custom or well-known insecure classes. For instance, `java.util.Random` produces an identical sequence of numbers for each given seed value; consequently, the sequence of numbers is predictable. Instead a well-vetted algorithm should be chosen that is currently considered to be strong by experts in the field, and a well-tested implementations with adequate length seeds should be used.\n\nIdentify all instances of `SecureRandom` that are not created using the default constructor. Specifying the seed value may reduce randomness. Use only the [no-argument constructor of `SecureRandom`](https://wiki.sei.cmu.edu/confluence/display/java/MSC02-J.+Generate+strong+random+numbers \"Generation of Strong Random Numbers\") that uses the system-specified seed value to generate a 128-byte-long random number.\n\nIn general, if a PRNG is not advertised as being cryptographically secure (e.g. `java.util.Random`), then it is probably a statistical PRNG and should not be used in security-sensitive contexts.\nPseudo-random number generators [can produce predictable numbers](https://wiki.sei.cmu.edu/confluence/display/java/MSC63-J.+Ensure+that+SecureRandom+is+properly+seeded \"Proper seeding of SecureRandom\") if the generator is known and the seed can be guessed. A 128-bit seed is a good starting point for producing a \"random enough\" number.\n\nOnce an attacker knows what type of weak pseudo-random number generator (PRNG) is used, it can be trivial to write a proof-of-concept to generate the next random value based on previously observed ones, as it was [done for Java Random](https://franklinta.com/2014/08/31/predicting-the-next-math-random-in-java/ \"Predicting the next Math.random() in Java\"). In case of very weak custom random generators it may be possible to observe the pattern statistically. Although the recommended approach would anyway be to decompile the APK and inspect the algorithm (see Static Analysis).\n\nIf you want to test for randomness, you can try to capture a large set of numbers and check with the Burp's [sequencer](https://portswigger.net/burp/documentation/desktop/tools/sequencer \"Burp\\'s Sequencer\") to see how good the quality of the randomness is."
  },
  {
    "id": "MASTG-TEST-0019",
    "title": "Mobile Security Test 0019",
    "category": "Android Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\n### Testing Network Requests over Secure Protocols\n\nFirst, you should identify all network requests in the source code and ensure that no plain HTTP URLs are used. Make sure that sensitive information is sent over secure channels by using [`HttpsURLConnection`](https://developer.android.com/reference/javax/net/ssl/HttpsURLConnection.html \"HttpsURLConnection\") or [`SSLSocket`](https://developer.android.com/reference/javax/net/ssl/SSLSocket.html \"SSLSocket\") (for socket-level communication using TLS).\n\n### Testing Network API Usage\n\nNext, even when using a low-level API which is supposed to make secure connections (such as `SSLSocket`), be aware that it has to be securely implemented. For instance, `SSLSocket` **doesn't** verify the hostname. Use `getDefaultHostnameVerifier` to verify the hostname. The Android developer documentation includes a [code example](https://developer.android.com/training/articles/security-ssl.html#WarningsSslSocket \"Warnings About Using SSLSocket Directly\").\n\n### Testing for Cleartext Traffic\n\nNext, you should ensure that the app is not allowing cleartext HTTP traffic. Since Android 9 (API level 28) cleartext HTTP traffic is blocked by default (thanks to the [default Network Security Configuration](../../../Document/0x05g-Testing-Network-Communication.md#default-configurations)) but there are multiple ways in which an application can still send it:\n\n- Setting the [`android:usesCleartextTraffic`](https://developer.android.com/guide/topics/manifest/application-element#usesCleartextTraffic \"Android documentation - usesCleartextTraffic flag\") attribute of the `<application>` tag in the AndroidManifest.xml file. Note that this flag is ignored in case the Network Security Configuration is configured.\n- Configuring the Network Security Configuration to enable cleartext traffic by setting the `cleartextTrafficPermitted` attribute to true on `<domain-config>` elements.\n- Using low-level APIs (e.g. [`Socket`](https://developer.android.com/reference/java/net/Socket \"Socket class\")) to set up a custom HTTP connection.\n- Using a cross-platform framework (e.g. Flutter, Xamarin, ...), as these typically have their own implementations for HTTP libraries.\n\nAll of the above cases must be carefully analyzed as a whole. For example, even if the app does not permit cleartext traffic in its Android Manifest or Network Security Configuration, it might actually still be sending HTTP traffic. That could be the case if it's using a low-level API (for which Network Security Configuration is ignored) or a badly configured cross-platform framework.\n\nFor more information refer to the article [\"Security with HTTPS and SSL\"](https://developer.android.com/training/articles/security-ssl.html)."
  },
  {
    "id": "MASTG-TEST-0020",
    "title": "Mobile Security Test 0020",
    "category": "Android Security Testing",
    "description": "Refer to section [\"Verifying the TLS Settings\"](../../../Document/0x04f-Testing-Network-Communication.md#verifying-the-tls-settings) in chapter \"Mobile App Network Communication\" for details.",
    "full_description": "Refer to section [\"Verifying the TLS Settings\"](../../../Document/0x04f-Testing-Network-Communication.md#verifying-the-tls-settings) in chapter \"Mobile App Network Communication\" for details."
  },
  {
    "id": "MASTG-TEST-0021",
    "title": "Mobile Security Test 0021",
    "category": "Android Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\nUsing TLS to transport sensitive information over the network is essential for security. However, encrypting communication between a mobile application and its backend API is not trivial. Developers often decide on simpler but less secure solutions (e.g., those that accept any certificate) to facilitate the development process, and sometimes these weak solutions [make it into the production version](https://saschafahl.de/static/paper/androidssl2012.pdf \"Hunting Down Broken SSL in Android Apps\"), potentially exposing users to [Machine-in-the-Middle (MITM)](../../../Document/0x04f-Testing-Network-Communication.md#intercepting-network-traffic-through-mitm) attacks. See [\"CWE-295: Improper Certificate Validation\"](https://cwe.mitre.org/data/definitions/295.html \"CWE-295: Improper Certificate Validation\").\n\nTwo key issues should be addressed:\n\n- Verify that a certificate comes from a trusted source, i.e. a trusted CA (Certificate Authority).\n- Determine whether the endpoint server presents the right certificate.\n\nMake sure that the hostname and the certificate itself are verified correctly. Examples and common pitfalls are available in the [official Android documentation](https://developer.android.com/training/articles/security-ssl.html \"Android Documentation - SSL\"). Search the code for examples of `TrustManager` and `HostnameVerifier` usage. In the sections below, you can find examples of the kind of insecure usage that you should look for.\n\n> Note that from Android 8.0 (API level 26) onward, there is no support for SSLv3 and `HttpsURLConnection` will no longer perform a fallback to an insecure TLS/SSL protocol.\n\n### Verifying the Target SDK Version\n\nApplications targeting Android 7.0 (API level 24) or higher will use a **default Network Security Configuration that doesn't trust any user supplied CAs**, reducing the possibility of MITM attacks by luring users to install malicious CAs.\n\nDecode the app using apktool (@MASTG-TECH-0007) and verify that the `targetSdkVersion` in apktool.yml is equal to or higher than `24`.\n\n```txt\ngrep targetSdkVersion UnCrackable-Level3/apktool.yml\n  targetSdkVersion: '28'\n```\n\nHowever, even if `targetSdkVersion >=24`, the developer can disable default protections by using a custom Network Security Configuration defining a custom trust anchor **forcing the app to trust user supplied CAs**. See [\"Analyzing Custom Trust Anchors\"](#analyzing-custom-trust-anchors).\n\n### Analyzing Custom Trust Anchors\n\nSearch for the [Network Security Configuration](../../../Document/0x05g-Testing-Network-Communication.md#android-network-security-configuration) file and inspect any custom `<trust-anchors>` defining `<certificates src=\"user\">` (which should be avoided).\n\nYou should carefully analyze the [precedence of entries](https://developer.android.com/training/articles/security-config#ConfigInheritance):\n\n- If a value is not set in a `<domain-config>` entry or in a parent `<domain-config>`, the configurations in place will be based on the `<base-config>`\n- If not defined in this entry, the [default configurations](../../../Document/0x05g-Testing-Network-Communication.md#default-configurations) will be used.\n\nTake a look at this example of a Network Security Configuration for an app targeting Android 9 (API level 28):\n\n```xml\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<network-security-config>\n    <domain-config>\n        <domain includeSubdomains=\"false\">owasp.org</domain>\n        <trust-anchors>\n            <certificates src=\"system\" />\n            <certificates src=\"user\" />\n        </trust-anchors>\n    </domain-config>\n</network-security-config>\n```\n\nSome observations:\n\n- There's no `<base-config>`, meaning that the [default configuration](../../../Document/0x05g-Testing-Network-Communication.md#default-configurations) for Android 9 (API level 28) or higher will be used for all other connections (only `system` CA will be trusted in principle).\n- However, the `<domain-config>` overrides the default configuration allowing the app to trust both `system` and `user` CAs for the indicated `<domain>` (owasp.org).\n- This doesn't affect subdomains because of `includeSubdomains=\"false\"`.\n\nPutting all together we can _translate_ the above Network Security Configuration to: \"the app trusts system and user CAs for the owasp.org domain, excluding its subdomains. For any other domains the app will trust the system CAs only\".\n\n### Verifying the Server Certificate\n\n`TrustManager` is a means of verifying conditions necessary for establishing a trusted connection in Android. The following conditions should be checked at this point:\n\n- Has the certificate been signed by a trusted CA?\n- Has the certificate expired?\n- Is the certificate self-signed?\n\nThe following code snippet is sometimes used during development and will accept any certificate, overwriting the functions `checkClientTrusted`, `checkServerTrusted`, and `getAcceptedIssuers`. Such implementations should be avoided, and, if they are necessary, they should be clearly separated from production builds to avoid built-in security flaws.\n\n```java\nTrustManager[] trustAllCerts = new TrustManager[] {\n    new X509TrustManager() {\n        @Override\n        public X509Certificate[] getAcceptedIssuers() {\n            return new java.security.cert.X509Certificate[] {};\n        }\n\n        @Override\n        public void checkClientTrusted(X509Certificate[] chain, String authType)\n            throws CertificateException {\n        }\n\n        @Override\n        public void checkServerTrusted(X509Certificate[] chain, String authType)\n            throws CertificateException {\n        }\n    }\n };\n\n// SSLContext context\ncontext.init(null, trustAllCerts, new SecureRandom());\n```\n\n### WebView Server Certificate Verification\n\nSometimes applications use a WebView to render the website associated with the application. This is true of HTML/JavaScript-based frameworks such as Apache Cordova, which uses an internal WebView for application interaction. When a WebView is used, the mobile browser performs the server certificate validation. Ignoring any TLS error that occurs when the WebView tries to connect to the remote website is a bad practice.\n\nThe following code will ignore TLS issues, exactly like the WebViewClient custom implementation provided to the WebView:\n\n```java\nWebView myWebView = (WebView) findViewById(R.id.webview);\nmyWebView.setWebViewClient(new WebViewClient(){\n    @Override\n    public void onReceivedSslError(WebView view, SslErrorHandler handler, SslError error) {\n        //Ignore TLS certificate errors and instruct the WebViewClient to load the website\n        handler.proceed();\n    }\n});\n```\n\n### Apache Cordova Certificate Verification\n\nImplementation of the Apache Cordova framework's internal WebView usage will ignore [TLS errors](https://github.com/apache/cordova-android/blob/master/framework/src/org/apache/cordova/engine/SystemWebViewClient.java \"TLS errors ignoring by Apache Cordova in WebView\") in the method `onReceivedSslError` if the flag `android:debuggable` is enabled in the application manifest. Therefore, make sure that the app is not debuggable. See the test case \"Testing If the App is Debuggable\".\n\n### Hostname Verification\n\nAnother security flaw in client-side TLS implementations is the lack of hostname verification. Development environments usually use internal addresses instead of valid domain names, so developers often disable hostname verification (or force an application to allow any hostname) and simply forget to change it when their application goes to production. The following code disables hostname verification:\n\n```java\nfinal static HostnameVerifier NO_VERIFY = new HostnameVerifier() {\n    public boolean verify(String hostname, SSLSession session) {\n        return true;\n    }\n};\n```\n\nWith a built-in `HostnameVerifier`, accepting any hostname is possible:\n\n```java\nHostnameVerifier NO_VERIFY = org.apache.http.conn.ssl.SSLSocketFactory\n                             .ALLOW_ALL_HOSTNAME_VERIFIER;\n```\n\nMake sure that your application verifies a hostname before setting a trusted connection."
  },
  {
    "id": "MASTG-TEST-0022",
    "title": "Mobile Security Test 0022",
    "category": "Android Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\n### Network Security Configuration\n\nInspect the Network Security Configuration looking for any `<pin-set>` elements. Check their `expiration` date, if any. If expired, certificate pinning will be disabled for the affected domains.\n\n> **Testing Tip**: If a certificate pinning validation check has failed, the following event should be logged in the system logs (see @MASTG-TECH-0009):\n\n```bash\nI/X509Util: Failed to validate the certificate chain, error: Pin verification failed\n```\n\n### TrustManager\n\nImplementing certificate pinning involves three main steps:\n\n- Obtain the certificate of the desired host(s).\n- Make sure the certificate is in .bks format.\n- Pin the certificate to an instance of the default Apache Httpclient.\n\nTo analyze the correct implementation of certificate pinning, the HTTP client should load the KeyStore:\n\n```java\nInputStream in = resources.openRawResource(certificateRawResource);\nkeyStore = KeyStore.getInstance(\"BKS\");\nkeyStore.load(resourceStream, password);\n```\n\nOnce the KeyStore has been loaded, we can use the TrustManager that trusts the CAs in our KeyStore:\n\n```java\nString tmfAlgorithm = TrustManagerFactory.getDefaultAlgorithm();\nTrustManagerFactory tmf = TrustManagerFactory.getInstance(tmfAlgorithm);\ntmf.init(keyStore);\n// Create an SSLContext that uses the TrustManager\n// SSLContext context = SSLContext.getInstance(\"TLS\");\nsslContext.init(null, tmf.getTrustManagers(), null);\n```\n\nThe app's implementation may be different, pinning against the certificate's public key only, the whole certificate, or a whole certificate chain.\n\n### Network Libraries and WebViews\n\nApplications that use third-party networking libraries may utilize the libraries' certificate pinning functionality. For example, [okhttp](https://github.com/square/okhttp/wiki/HTTPS \"okhttp library\") can be set up with the `CertificatePinner` as follows:\n\n```java\nOkHttpClient client = new OkHttpClient.Builder()\n        .certificatePinner(new CertificatePinner.Builder()\n            .add(\"example.com\", \"sha256/UwQAapahrjCOjYI3oLUx5AQxPBR02Jz6/E2pt0IeLXA=\")\n            .build())\n        .build();\n```\n\nApplications that use a WebView component may utilize the WebViewClient's event handler for some kind of \"certificate pinning\" of each request before the target resource is loaded. The following code shows an example verification:\n\n```java\nWebView myWebView = (WebView) findViewById(R.id.webview);\nmyWebView.setWebViewClient(new WebViewClient(){\n    private String expectedIssuerDN = \"CN=Let's Encrypt Authority X3,O=Let's Encrypt,C=US;\";\n\n    @Override\n    public void onLoadResource(WebView view, String url)  {\n        //From Android API documentation about \"WebView.getCertificate()\":\n        //Gets the SSL certificate for the main top-level page\n        //or null if there is no certificate (the site is not secure).\n        //\n        //Available information on SslCertificate class are \"Issuer DN\", \"Subject DN\" and validity date helpers\n        SslCertificate serverCert = view.getCertificate();\n        if(serverCert != null){\n            //apply either certificate or public key pinning comparison here\n                //Throw exception to cancel resource loading...\n            }\n        }\n    }\n});\n```\n\nAlternatively, it is better to use an OkHttpClient with configured pins and let it act as a proxy overriding `shouldInterceptRequest` of the `WebViewClient`.\n\n### Xamarin Applications\n\nApplications developed in Xamarin will typically use `ServicePointManager` to implement pinning.\n\nNormally a function is created to check the certificate(s) and return the boolean value to the method `ServerCertificateValidationCallback`:\n\n```cs\n[Activity(Label = \"XamarinPinning\", MainLauncher = true)]\n    public class MainActivity : Activity\n    {\n        // SupportedPublicKey - Hexadecimal value of the public key.\n        // Use GetPublicKeyString() method to determine the public key of the certificate we want to pin. Uncomment the debug code in the ValidateServerCertificate function a first time to determine the value to pin.\n        private const string SupportedPublicKey = \"3082010A02820101009CD30CF05AE52E47B7725D3783B...\"; // Shortened for readability\n\n        private static bool ValidateServerCertificate(\n                object sender,\n                X509Certificate certificate,\n                X509Chain chain,\n                SslPolicyErrors sslPolicyErrors\n            )\n        {\n            //Log.Debug(\"Xamarin Pinning\",chain.ChainElements[X].Certificate.GetPublicKeyString());\n            //return true;\n            return SupportedPublicKey == chain.ChainElements[1].Certificate.GetPublicKeyString();\n        }\n\n        protected override void OnCreate(Bundle savedInstanceState)\n        {\n            System.Net.ServicePointManager.ServerCertificateValidationCallback += ValidateServerCertificate;\n            base.OnCreate(savedInstanceState);\n            SetContentView(Resource.Layout.Main);\n            TesteAsync(\"https://security.claudio.pt\");\n\n        }\n```\n\nIn this particular example we are pinning the intermediate CA of the certificate chain. The output of the HTTP response will be available in the system logs.\n\nSample Xamarin app with the previous example can be obtained on the [MASTG repository](https://github.com/OWASP/mastg/raw/master/Samples/Android/02_CertificatePinning/certificatePinningXamarin.apk \"Xamarin app with certificate pinning\")\n\nAfter decompressing the APK file, use a .NET decompiler like dotPeak, ILSpy or dnSpy to decompile the app dlls stored inside the 'Assemblies' folder and confirm the usage of the ServicePointManager.\n\nLearn more:\n\n- Certificate and Public Key Pinning with Xamarin - <https://thomasbandt.com/certificate-and-public-key-pinning-with-xamarin>\n- ServicePointManager - <https://msdn.microsoft.com/en-us/library/system.net.servicepointmanager(v=vs.110).aspx>\n\n### Cordova Applications\n\nHybrid applications based on Cordova do not support Certificate Pinning natively, so plugins are used to achieve this. The most common one is [PhoneGap SSL Certificate Checker](https://github.com/EddyVerbruggen/SSLCertificateChecker-PhoneGap-Plugin \"PhoneGap SSL Certificate Checker plugin\"). The `check` method is used to confirm the fingerprint and callbacks will determine the next steps.\n\n```javascript\n  // Endpoint to verify against certificate pinning.\n  var server = \"https://www.owasp.org\";\n  // SHA256 Fingerprint (Can be obtained via \"openssl s_client -connect hostname:443 | openssl x509 -noout -fingerprint -sha256\"\n  var fingerprint = \"D8 EF 3C DF 7E F6 44 BA 04 EC D5 97 14 BB 00 4A 7A F5 26 63 53 87 4E 76 67 77 F0 F4 CC ED 67 B9\";\n\n  window.plugins.sslCertificateChecker.check(\n          successCallback,\n          errorCallback,\n          server,\n          fingerprint);\n\n   function successCallback(message) {\n     alert(message);\n     // Message is always: CONNECTION_SECURE.\n     // Now do something with the trusted server.\n   }\n\n   function errorCallback(message) {\n     alert(message);\n     if (message === \"CONNECTION_NOT_SECURE\") {\n       // There is likely a MITM attack going on, be careful!\n     } else if (message.indexOf(\"CONNECTION_FAILED\") >- 1) {\n       // There was no connection (yet). Internet may be down. Try again (a few times) after a little timeout.\n     }\n   }\n```\n\nAfter decompressing the APK file, Cordova/Phonegap files will be located in the /assets/www folder. The 'plugins' folder will give you the visibility of the plugins used. We will need to search for this methods in the JavaScript code of the application to confirm its usage."
  },
  {
    "id": "MASTG-TEST-0023",
    "title": "Mobile Security Test 0023",
    "category": "Android Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\nApplications based on the Android SDK should depend on GooglePlayServices. For example, in the gradle build file, you will find `compile 'com.google.android.gms:play-services-gcm:x.x.x'` in the dependencies block. You need to make sure that the `ProviderInstaller` class is called with either `installIfNeeded` or `installIfNeededAsync`. `ProviderInstaller` needs to be called by a component of the application as early as possible. Exceptions thrown by these methods should be caught and handled correctly. If the application cannot patch its security provider, it can either inform the API of its less secure state or restrict user actions (because all HTTPS traffic should be deemed riskier in this situation).\n\nIf you have access to the source code, check if the app handle any exceptions related to the security provider updates properly, and if it reports to the backend when the application is working with an unpatched security provider. The Android Developer documentation provides different examples showing [how to update the Security Provider to prevent SSL exploits](https://developer.android.com/privacy-and-security/security-gms-provider \"Updating Your Security Provider to Protect Against SSL Exploits\").\n\nLastly, make sure that NDK-based applications bind only to a recent and properly patched library that provides SSL/TLS functionality."
  },
  {
    "id": "MASTG-TEST-0007",
    "title": "Mobile Security Test 0007",
    "category": "Android Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\nThe first step is to look at `AndroidManifest.xml` to detect content providers exposed by the app. You can identify content providers by the `<provider>` element. Complete the following steps:\n\n- Determine whether the value of the export tag (`android:exported`) is `\"true\"`. Even if it is not, the tag will be set to `\"true\"` automatically if an `<intent-filter>` has been defined for the tag. If the content is meant to be accessed only by the app itself, set `android:exported` to `\"false\"`. If not, set the flag to `\"true\"` and define proper read/write permissions.\n- Determine whether the data is being protected by a permission tag (`android:permission`). Permission tags limit exposure to other apps.\n- Determine whether the `android:protectionLevel` attribute has the value `signature`. This setting indicates that the data is intended to be accessed only by apps from the same enterprise (i.e., signed with the same key). To make the data accessible to other apps, apply a security policy with the `<permission>` element and set a proper `android:protectionLevel`. If you use `android:permission`, other applications must declare corresponding `<uses-permission>` elements in their manifests to interact with your content provider. You can use the `android:grantUriPermissions` attribute to grant more specific access to other apps; you can limit access with the `<grant-uri-permission>` element.\n\nInspect the source code to understand how the content provider is meant to be used. Search for the following keywords:\n\n- `android.content.ContentProvider`\n- `android.database.Cursor`\n- `android.database.sqlite`\n- `.query`\n- `.update`\n- `.delete`\n\n> To avoid SQL injection attacks within the app, use parameterized query methods, such as `query`, `update`, and `delete`. Be sure to properly sanitize all method arguments; for example, the `selection` argument could lead to SQL injection if it is made up of concatenated user input.\n\n If you expose a content provider, determine whether parameterized [query methods](https://developer.android.com/reference/android/content/ContentProvider.html#query%28android.net.Uri%2C%20java.lang.String[]%2C%20java.lang.String%2C%20java.lang.String[]%2C%20java.lang.String%29 \"Query method in ContentProvider Class\") (`query`, `update`, and `delete`) are being used to prevent SQL injection. If so, make sure all their arguments are properly sanitized.\n\nWe will use the vulnerable password manager app [Sieve](https://github.com/mwrlabs/drozer/releases/download/2.3.4/sieve.apk \"Sieve - Vulnerable Password Manager\") as an example of a vulnerable content provider.\n\n### Inspect the Android Manifest\n\nIdentify all defined `<provider>` elements:\n\n```xml\n<provider\n      android:authorities=\"com.mwr.example.sieve.DBContentProvider\"\n      android:exported=\"true\"\n      android:multiprocess=\"true\"\n      android:name=\".DBContentProvider\">\n    <path-permission\n          android:path=\"/Keys\"\n          android:readPermission=\"com.mwr.example.sieve.READ_KEYS\"\n          android:writePermission=\"com.mwr.example.sieve.WRITE_KEYS\"\n     />\n</provider>\n<provider\n      android:authorities=\"com.mwr.example.sieve.FileBackupProvider\"\n      android:exported=\"true\"\n      android:multiprocess=\"true\"\n      android:name=\".FileBackupProvider\"\n/>\n```\n\nAs shown in the `AndroidManifest.xml` above, the application exports two content providers. Note that one path (\"/Keys\") is protected by read and write permissions.\n\n### Inspect the source code\n\nInspect the `query` function in the `DBContentProvider.java` file to determine whether any sensitive information is being leaked:\n\nExample in Java:\n\n```java\npublic Cursor query(final Uri uri, final String[] array, final String s, final String[] array2, final String s2) {\n    final int match = this.sUriMatcher.match(uri);\n    final SQLiteQueryBuilder sqLiteQueryBuilder = new SQLiteQueryBuilder();\n    if (match >= 100 && match < 200) {\n        sqLiteQueryBuilder.setTables(\"Passwords\");\n    }\n    else if (match >= 200) {\n        sqLiteQueryBuilder.setTables(\"Key\");\n    }\n    return sqLiteQueryBuilder.query(this.pwdb.getReadableDatabase(), array, s, array2, (String)null, (String)null, s2);\n}\n```\n\nExample in Kotlin:\n\n```kotlin\nfun query(uri: Uri?, array: Array<String?>?, s: String?, array2: Array<String?>?, s2: String?): Cursor {\n        val match: Int = this.sUriMatcher.match(uri)\n        val sqLiteQueryBuilder = SQLiteQueryBuilder()\n        if (match >= 100 && match < 200) {\n            sqLiteQueryBuilder.tables = \"Passwords\"\n        } else if (match >= 200) {\n            sqLiteQueryBuilder.tables = \"Key\"\n        }\n        return sqLiteQueryBuilder.query(this.pwdb.getReadableDatabase(), array, s, array2, null as String?, null as String?, s2)\n    }\n```\n\nHere we see that there are actually two paths, \"/Keys\" and \"/Passwords\", and the latter is not being protected in the manifest and is therefore vulnerable.\n\n When accessing a URI, the query statement returns all passwords and the path `Passwords/`. We will address this in the \"Dynamic Analysis\" section and show the exact URI that is required."
  },
  {
    "id": "MASTG-TEST-0008",
    "title": "Mobile Security Test 0008",
    "category": "Android Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\nCarefully review all UI components that either show such information or take it as input. Search for any traces of sensitive information and evaluate if it should be masked or completely removed.\n\n### Text Fields\n\nTo make sure an application is masking sensitive user input, check for the following attribute in the definition of `EditText`:\n\n```xml\nandroid:inputType=\"textPassword\"\n```\n\nWith this setting, dots (instead of the input characters) will be displayed in the text field, preventing the app from leaking passwords or pins to the user interface.\n\n### App Notifications\n\nWhen statically assessing an application, it is recommended to search for any usage of the `NotificationManager` class which might be an indication of some form of notification management. If the class is being used, the next step would be to understand how the application is [generating the notifications](https://developer.android.com/training/notify-user/build-notification#SimpleNotification \"Create a Notification\").\n\nThese code locations can be fed into the Dynamic Analysis section below, providing an idea of where in the application notifications may be dynamically generated."
  },
  {
    "id": "MASTG-TEST-0010",
    "title": "Mobile Security Test 0010",
    "category": "Android Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\nA screenshot of the current activity is taken when an Android app goes into background and displayed for aesthetic purposes when the app returns to the foreground. However, this may leak sensitive information.\n\nTo determine whether the application may expose sensitive information via the app switcher, find out whether the [`FLAG_SECURE`](https://developer.android.com/reference/android/view/Display.html#FLAG_SECURE \"FLAG_SECURE Option\") option has been set. You should find something similar to the following code snippet:\n\nExample in Java:\n\n```java\ngetWindow().setFlags(WindowManager.LayoutParams.FLAG_SECURE,\n                WindowManager.LayoutParams.FLAG_SECURE);\n\nsetContentView(R.layout.activity_main);\n```\n\nExample in Kotlin:\n\n```kotlin\nwindow.setFlags(WindowManager.LayoutParams.FLAG_SECURE,\n                WindowManager.LayoutParams.FLAG_SECURE)\n\nsetContentView(R.layout.activity_main)\n```\n\nIf the option has not been set, the application is vulnerable to screen capturing."
  },
  {
    "id": "MASTG-TEST-0024",
    "title": "Mobile Security Test 0024",
    "category": "Android Security Testing",
    "description": "When testing [app permissions](../../../Document/0x05h-Testing-Platform-Interaction.md#app-permissions \"App Permissions\") the goal is to try and reduce the amount of permissions used by your app to th...",
    "full_description": "When testing [app permissions](../../../Document/0x05h-Testing-Platform-Interaction.md#app-permissions \"App Permissions\") the goal is to try and reduce the amount of permissions used by your app to the absolute minimum. While going through each permission, remember that it is best practice first to try and [evaluate whether your app needs to use this permission](https://developer.android.com/training/permissions/evaluating) because many functionalities such as taking a photo can be done without, limiting the amount of access to sensitive data. If permissions are required you will then make sure that the request/response to access the permission is handled handled correctly."
  },
  {
    "id": "MASTG-TEST-0028",
    "title": "Mobile Security Test 0028",
    "category": "Android Security Testing",
    "description": "Any existing [deep links](../../../Document/0x05h-Testing-Platform-Interaction.md#deep-links \"Deep Links\") (including App Links) can potentially increase the app attack surface. This [includes many ri...",
    "full_description": "Any existing [deep links](../../../Document/0x05h-Testing-Platform-Interaction.md#deep-links \"Deep Links\") (including App Links) can potentially increase the app attack surface. This [includes many risks](https://people.cs.vt.edu/gangwang/deep17.pdf) such as link hijacking, sensitive functionality exposure, etc.\n\n- Before Android 12 (API level 31), if the app has any [non-verifiable links](https://developer.android.com/training/app-links/verify-android-applinks#fix-errors), it can cause the system to not verify all Android App Links for that app.\n- Starting on Android 12 (API level 31), apps benefit from a [reduced attack surface](https://developer.android.com/training/app-links/deep-linking). A generic web intent resolves to the user's default browser app unless the target app is approved for the specific domain contained in that web intent.\n\nAll deep links must be enumerated and verified for correct website association. The actions they perform must be well tested, especially all input data, which should be deemed untrustworthy and thus should always be validated.\n\nNone of the input from these sources can be trusted; it must be validated and/or sanitized. Validation ensures processing of data that the app is expecting only. If validation is not enforced, any input can be sent to the app, which may allow an attacker or malicious app to exploit app functionality."
  },
  {
    "id": "MASTG-TEST-0029",
    "title": "Start the activity without specifying an action or an category",
    "category": "Android Security Testing",
    "description": "To test for [sensitive functionality exposure through IPC](../../../Document/0x05h-Testing-Platform-Interaction.md#sensitive-functionality-exposure-through-ipc \"Sensitive Functionality Exposure Throug...",
    "full_description": "To test for [sensitive functionality exposure through IPC](../../../Document/0x05h-Testing-Platform-Interaction.md#sensitive-functionality-exposure-through-ipc \"Sensitive Functionality Exposure Through IPC\") mechanisms you should first enumerate all the IPC mechanisms the app uses and then try to identify whether sensitive data is leaked when the mechanisms are used."
  },
  {
    "id": "MASTG-TEST-0030",
    "title": "Mobile Security Test 0030",
    "category": "Android Security Testing",
    "description": "When testing [Pending Intents](../../../Document/0x05h-Testing-Platform-Interaction.md#pending-intents) you must ensure that they are immutable and that the app explicitly specifies the exact package,...",
    "full_description": "When testing [Pending Intents](../../../Document/0x05h-Testing-Platform-Interaction.md#pending-intents) you must ensure that they are immutable and that the app explicitly specifies the exact package, action, and component that will receive the base intent."
  },
  {
    "id": "MASTG-TEST-0031",
    "title": "Mobile Security Test 0031",
    "category": "Android Security Testing",
    "description": "To test for [JavaScript execution in WebViews](../../../Document/0x05h-Testing-Platform-Interaction.md#javascript-execution-in-webviews \"JavaScript Execution in WebViews\") check the app for WebView us...",
    "full_description": "To test for [JavaScript execution in WebViews](../../../Document/0x05h-Testing-Platform-Interaction.md#javascript-execution-in-webviews \"JavaScript Execution in WebViews\") check the app for WebView usage and evaluate whether or not each WebView should allow JavaScript execution. If JavaScript execution is required for the app to function normally, then you need to ensure that the app follows the all best practices."
  },
  {
    "id": "MASTG-TEST-0032",
    "title": "Mobile Security Test 0032",
    "category": "Android Security Testing",
    "description": "To test for [WebView protocol handlers (or resource access)](../../../Document/0x05h-Testing-Platform-Interaction.md#webview-local-file-access-settings) check the app for WebView usage and evaluate wh...",
    "full_description": "To test for [WebView protocol handlers (or resource access)](../../../Document/0x05h-Testing-Platform-Interaction.md#webview-local-file-access-settings) check the app for WebView usage and evaluate whether or not the WebView should have resource access. If resource access is necessary you need to verify that it's implemented following best practices."
  },
  {
    "id": "MASTG-TEST-0033",
    "title": "Mobile Security Test 0033",
    "category": "Android Security Testing",
    "description": "To test for [Java objects exposed through WebViews](../../../Document/0x05h-Testing-Platform-Interaction.md#java-objects-exposed-through-webviews \"Java Objects Exposed Through WebViews\") check the app...",
    "full_description": "To test for [Java objects exposed through WebViews](../../../Document/0x05h-Testing-Platform-Interaction.md#java-objects-exposed-through-webviews \"Java Objects Exposed Through WebViews\") check the app for WebViews having JavaScript enabled and determine whether the WebView is creating any JavaScript interfaces aka. \"JavaScript Bridges\". Finally, check whether an attacker could potentially inject malicious JavaScript code."
  },
  {
    "id": "MASTG-TEST-0035",
    "title": "Mobile Security Test 0035",
    "category": "Android Security Testing",
    "description": "To test for [overlay attacks](../../../Document/0x05h-Testing-Platform-Interaction.md#overlay-attacks \"Overlay Attacks\") you need to check the app for usage of certain APIs and attributed typically us...",
    "full_description": "To test for [overlay attacks](../../../Document/0x05h-Testing-Platform-Interaction.md#overlay-attacks \"Overlay Attacks\") you need to check the app for usage of certain APIs and attributed typically used to protect against overlay attacks as well as check the Android version that app is targeting.\n\nTo mitigate these attacks please carefully read the general guidelines about Android View security in the [Android Developer Documentation](https://developer.android.com/reference/android/view/View#security \"View Security\"). For instance, the so-called _touch filtering_ is a common defense against tapjacking, which contributes to safeguarding users against these vulnerabilities, usually in combination with other techniques and considerations as we introduce in this section."
  },
  {
    "id": "MASTG-TEST-0037",
    "title": "Mobile Security Test 0037",
    "category": "Android Security Testing",
    "description": "To test for [WebViews cleanup](../../../Document/0x05h-Testing-Platform-Interaction.md#webviews-cleanup \"WebViews Cleanup\") you should inspect all APIs related to WebView data deletion and try to full...",
    "full_description": "To test for [WebViews cleanup](../../../Document/0x05h-Testing-Platform-Interaction.md#webviews-cleanup \"WebViews Cleanup\") you should inspect all APIs related to WebView data deletion and try to fully track the data deletion process."
  },
  {
    "id": "MASTG-TEST-0038",
    "title": "Mobile Security Test 0038",
    "category": "Android Security Testing",
    "description": "Ensure that the release builds are properly signed to safeguard their integrity and protect them from tampering. Android has evolved its signing schemes over time to enhance security, with newer versi...",
    "full_description": "Ensure that the release builds are properly signed to safeguard their integrity and protect them from tampering. Android has evolved its signing schemes over time to enhance security, with newer versions offering more robust mechanisms.\n\n- **Android 7.0 (API level 24) and above**: Use at least the **v2 signature scheme**, which signs the APK as a whole, providing stronger protection compared to the older v1 (JAR) signing method.\n- **Android 9 (API level 28) and above**: It's recommended to use both the **v2 and v3 signature schemes**. The v3 scheme supports **key rotation**, enabling developers to replace keys in the event of a compromise without invalidating old signatures.\n- **Android 11 (API level 30) and above**: Optionally include the **v4 signature scheme** to enable faster incremental updates.\n\nAvoid using the **v1 signature scheme** (JAR signing) unless absolutely necessary for backward compatibility with Android 6.0 (API level 23) and below as it is considered insecure. For example, it is affected by the **Janus vulnerability (CVE-2017-13156)**, which can allow malicious actors to modify APK files without invalidating the v1 signature. As such, **v1 should never be relied on exclusively for devices running Android 7.0 and above**.\n\nYou should also ensure that the APK's code-signing certificate is valid and belongs to the developer.\n\nFor further guidance, refer to the official [Android app signing documentation](https://developer.android.com/studio/publish/app-signing) and best practices for [configuring apps for release](https://developer.android.com/tools/publishing/preparing.html#publishing-configure)."
  },
  {
    "id": "MASTG-TEST-0039",
    "title": "If the command print 1 then the directive is present",
    "category": "Android Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\nCheck `AndroidManifest.xml` to determine whether the `android:debuggable` attribute has been set and to find the attribute's value:\n\n```xml\n    ...\n    <application android:allowBackup=\"true\" android:debuggable=\"true\" android:icon=\"@drawable/ic_launcher\" android:label=\"@string/app_name\" android:theme=\"@style/AppTheme\">\n    ...\n```\n\nYou can use `aapt` tool from the Android SDK with the following command line to quickly check if the `android:debuggable=\"true\"` directive is present:\n\n```bash\n# If the command print 1 then the directive is present\n# The regex search for this line: android:debuggable(0x0101000f)=(type 0x12)0xffffffff\n$ aapt d xmltree sieve.apk AndroidManifest.xml | grep -Ec \"android:debuggable\\(0x[0-9a-f]+\\)=\\(type\\s0x[0-9a-f]+\\)0xffffffff\"\n1\n```\n\nFor a release build, this attribute should always be set to `\"false\"` (the default value)."
  },
  {
    "id": "MASTG-TEST-0040",
    "title": "Mobile Security Test 0040",
    "category": "Android Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\nSymbols are usually stripped during the build process, so you need the compiled bytecode and libraries to make sure that unnecessary metadata has been discarded.\n\nFirst, find the `nm` binary in your Android NDK and export it (or create an alias).\n\n```bash\nexport NM = $ANDROID_NDK_DIR/toolchains/arm-linux-androideabi-4.9/prebuilt/darwin-x86_64/bin/arm-linux-androideabi-nm\n```\n\nTo display debug symbols:\n\n```bash\n$NM -a libfoo.so\n/tmp/toolchains/arm-linux-androideabi-4.9/prebuilt/darwin-x86_64/bin/arm-linux-androideabi-nm: libfoo.so: no symbols\n```\n\nTo display dynamic symbols:\n\n```bash\n$NM -D libfoo.so\n```\n\nAlternatively, open the file in your favorite disassembler and check the symbol tables manually.\n\nDynamic symbols can be stripped via the `visibility` compiler flag. Adding this flag causes gcc to discard the function names while preserving the names of functions declared as `JNIEXPORT`.\n\nMake sure that the following has been added to build.gradle:\n\n```default\nexternalNativeBuild {\n    cmake {\n        cppFlags \"-fvisibility=hidden\"\n    }\n}\n```"
  },
  {
    "id": "MASTG-TEST-0041",
    "title": "Mobile Security Test 0041",
    "category": "Android Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\nTo determine whether [`StrictMode`](https://developer.android.com/reference/android/os/StrictMode) is enabled, you can look for the `StrictMode.setThreadPolicy` or `StrictMode.setVmPolicy` methods. Most likely, they will be in the `onCreate` method.\n\nThe detection methods for the thread policy are:\n\n- `detectDiskWrites()`\n- `detectDiskReads()`\n- `detectNetwork()`\n\nThe penalties for thread policy violation are:\n\n- `penaltyLog()`: Logs a message to LogCat.\n- `penaltyDeath()`: Crashes application, runs at the end of all enabled penalties.\n- `penaltyDialog()`: Shows a dialog.\n\nHave a look at the [best practices](https://code.tutsplus.com/tutorials/android-best-practices-strictmode--mobile-7581 \"Android Best Practices: StrictMode\") for using StrictMode."
  },
  {
    "id": "MASTG-TEST-0045",
    "title": "Mobile Security Test 0045",
    "category": "Android Security Testing",
    "description": "Mobile application security test as per OWASP MASTG guidelines.",
    "full_description": "Mobile application security test as per OWASP MASTG guidelines."
  },
  {
    "id": "MASTG-TEST-0046",
    "title": "Mobile Security Test 0046",
    "category": "Android Security Testing",
    "description": "Mobile application security test as per OWASP MASTG guidelines.",
    "full_description": "Mobile application security test as per OWASP MASTG guidelines."
  },
  {
    "id": "MASTG-TEST-0047",
    "title": "Mobile Security Test 0047",
    "category": "Android Security Testing",
    "description": "Mobile application security test as per OWASP MASTG guidelines.",
    "full_description": "Mobile application security test as per OWASP MASTG guidelines."
  },
  {
    "id": "MASTG-TEST-0048",
    "title": "Mobile Security Test 0048",
    "category": "Android Security Testing",
    "description": "Mobile application security test as per OWASP MASTG guidelines.",
    "full_description": "Mobile application security test as per OWASP MASTG guidelines."
  },
  {
    "id": "MASTG-TEST-0049",
    "title": "Mobile Security Test 0049",
    "category": "Android Security Testing",
    "description": "Mobile application security test as per OWASP MASTG guidelines.",
    "full_description": "Mobile application security test as per OWASP MASTG guidelines."
  },
  {
    "id": "MASTG-TEST-0050",
    "title": "Mobile Security Test 0050",
    "category": "Android Security Testing",
    "description": "Mobile application security test as per OWASP MASTG guidelines.",
    "full_description": "Mobile application security test as per OWASP MASTG guidelines."
  },
  {
    "id": "MASTG-TEST-0051",
    "title": "Mobile Security Test 0051",
    "category": "Android Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\nDecompile the APK (@MASTG-TECH-0017) and review it (@MASTG-TECH-0023) to determine whether the codebase has been obfuscated.\n\nBelow you can find a sample for an obfuscated code block:\n\n```java\npackage com.a.a.a;\n\nimport com.a.a.b.a;\nimport java.util.List;\n\nclass a$b\n  extends a\n{\n  public a$b(List paramList)\n  {\n    super(paramList);\n  }\n\n  public boolean areAllItemsEnabled()\n  {\n    return true;\n  }\n\n  public boolean isEnabled(int paramInt)\n  {\n    return true;\n  }\n}\n```\n\nHere are some considerations:\n\n- Meaningful identifiers, such as class names, method names, and variable names, might have been discarded.\n- String resources and strings in binaries might have been encrypted.\n- Code and data related to the protected functionality might be encrypted, packed, or otherwise concealed.\n\nFor native code:\n\n- [libc APIs](https://man7.org/linux/man-pages/dir_section_3.html) (e.g open, read) might have been replaced with OS [syscalls](https://man7.org/linux/man-pages/man2/syscalls.2.html).\n- [Obfuscator-LLVM](https://github.com/obfuscator-llvm/obfuscator \"Obfuscator-LLVM\") might have been applied to perform [\"Control Flow Flattening\"](https://github.com/obfuscator-llvm/obfuscator/wiki/Control-Flow-Flattening) or [\"Bogus Control Flow\"](https://github.com/obfuscator-llvm/obfuscator/wiki/Bogus-Control-Flow).\n\nSome of these techniques are discussed and analyzed in the blog post [\"Security hardening of Android native code\"](https://darvincitech.wordpress.com/2020/01/07/security-hardening-of-android-native-code/) by Gautam Arvind and in the [\"APKiD: Fast Identification of AppShielding Products\"](https://github.com/enovella/cve-bio-enovella/blob/master/slides/APKiD-NowSecure-Connect19-enovella.pdf) presentation by Eduardo Novella.\n\nFor a more detailed assessment, you need a detailed understanding of the relevant threats and the obfuscation methods used. Tools such as @MASTG-TOOL-0009 may give you additional indications about which techniques were used for the target app such as obfuscators, packers and anti-debug measures."
  },
  {
    "id": "MASTG-TEST-0001",
    "title": "Mobile Security Test 0001",
    "category": "Android Security Testing",
    "description": "This test case focuses on identifying potentially sensitive data stored by an application and verifying if it is securely stored. The following checks should be performed:",
    "full_description": "This test case focuses on identifying potentially sensitive data stored by an application and verifying if it is securely stored. The following checks should be performed:\n\n- Analyze data storage in the source code.\n- Be sure to trigger all possible functionality in the application (e.g. by clicking everywhere possible) in order to ensure data generation.\n- Check all application generated and modified files and ensure that the storage method is sufficiently secure.\n    - This includes `SharedPreferences`, databases, Internal Storage, External Storage, etc.\n\n**NOTE:** For MASVS L1 compliance, it is sufficient to store data unencrypted in the application's internal storage directory (sandbox). For L2 compliance, additional encryption is required using cryptographic keys securely managed in the Android KeyStore. This includes using envelope encryption (DEK+KEK) or equivalent methods, or using the Android Security Library's [`EncryptedFile`](https://developer.android.com/reference/androidx/security/crypto/EncryptedFile)/[`EncryptedSharedPreferences`](https://developer.android.com/reference/androidx/security/crypto/EncryptedSharedPreferences).\n\n!!! Warning\n\n    The **Jetpack security crypto library**, including the `EncryptedFile` and  `EncryptedSharedPreferences` classes, has been [deprecated](https://developer.android.com/privacy-and-security/cryptography#jetpack_security_crypto_library). However, since an official replacement has not yet been released, we recommend using these classes until one is available."
  },
  {
    "id": "MASTG-TEST-0003",
    "title": "Mobile Security Test 0003",
    "category": "Android Security Testing",
    "description": "This test case focuses on identifying any sensitive application data within both system and application logs. The following checks should be performed:",
    "full_description": "This test case focuses on identifying any sensitive application data within both system and application logs. The following checks should be performed:\n\n- Analyze source code for logging related code.\n- Check application data directory for log files.\n- Gather system messages and logs and analyze for any sensitive data.\n\nAs a general recommendation to avoid potential sensitive application data leakage, logging statements should be removed from production releases unless deemed necessary to the application or explicitly identified as safe, e.g. as a result of a security audit."
  },
  {
    "id": "MASTG-TEST-0004",
    "title": "Mobile Security Test 0004",
    "category": "Android Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\nTo determine whether API calls and functions provided by the third-party library are used according to best practices, review their source code, requested permissions and check for any known vulnerabilities.\n\nAll data that's sent to third-party services should be anonymized to prevent exposure of PII (Personal Identifiable Information) that would allow the third party to identify the user account. No other data (such as IDs that can be mapped to a user account or session) should be sent to a third party."
  },
  {
    "id": "MASTG-TEST-0005",
    "title": "Mobile Security Test 0005",
    "category": "Android Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\nSearch for any usage of the `NotificationManager` class which might be an indication of some form of notification management. If the class is being used, the next step would be to understand how the application is [generating the notifications](https://developer.android.com/training/notify-user/build-notification#SimpleNotification \"Create a Notification\") and which data ends up being shown."
  },
  {
    "id": "MASTG-TEST-0006",
    "title": "Mobile Security Test 0006",
    "category": "Android Security Testing",
    "description": "Mobile application security test as per OWASP MASTG guidelines.",
    "full_description": "Mobile application security test as per OWASP MASTG guidelines."
  },
  {
    "id": "MASTG-TEST-0009",
    "title": "Mobile Security Test 0009",
    "category": "Android Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\n### Local\n\nCheck the `AndroidManifest.xml` file for the following flag:\n\n```xml\nandroid:allowBackup=\"true\"\n```\n\nIf the flag value is **true**, determine whether the app saves any kind of sensitive data (check the test case \"Testing for Sensitive Data in Local Storage\").\n\n### Cloud\n\nRegardless of whether you use key/value backup or auto backup, you must determine the following:\n\n- which files are sent to the cloud (e.g., SharedPreferences)\n- whether the files contain sensitive information\n- whether sensitive information is encrypted before being sent to the cloud.\n\n> If you don't want to share files with Google Cloud, you can exclude them from [Auto Backup](https://developer.android.com/guide/topics/data/autobackup.html#IncludingFiles \"Exclude files from Auto Backup\"). Sensitive information stored at rest on the device should be encrypted before being sent to the cloud.\n\n- **Auto Backup**: You configure Auto Backup via the boolean attribute `android:allowBackup` within the application's manifest file. [Auto Backup](https://developer.android.com/guide/topics/data/autobackup.html#EnablingAutoBackup \"Enabling AutoBackup\") is enabled by default for applications that target Android 6.0 (API level 23). You can use the attribute `android:fullBackupOnly` to activate auto backup when implementing a backup agent, but this attribute is available for Android versions 6.0 and above only. Other Android versions use key/value backup instead.\n\n```xml\nandroid:fullBackupOnly\n```\n\nAuto backup includes almost all the app files and stores up 25 MB of them per app in the user's Google Drive account. Only the most recent backup is stored; the previous backup is deleted.\n\n- **Key/Value Backup**: To enable key/value backup, you must define the backup agent in the manifest file. Look in `AndroidManifest.xml` for the following attribute:\n\n```xml\nandroid:backupAgent\n```\n\nTo implement key/value backup, extend one of the following classes:\n\n- [BackupAgent](https://developer.android.com/reference/android/app/backup/BackupAgent.html \"BackupAgent\")\n- [BackupAgentHelper](https://developer.android.com/reference/android/app/backup/BackupAgentHelper.html \"BackupAgentHelper\")\n\nTo check for key/value backup implementations, look for these classes in the source code."
  },
  {
    "id": "MASTG-TEST-0011",
    "title": "using strings",
    "category": "Android Security Testing",
    "description": "Analyzing memory can help developers identify the root causes of several problems, such as application crashes. However, it can also be used to access sensitive data. This section describes how to che...",
    "full_description": "Analyzing memory can help developers identify the root causes of several problems, such as application crashes. However, it can also be used to access sensitive data. This section describes how to check for data disclosure via process memory.\n\nFirst identify sensitive information that is stored in memory. Sensitive assets have likely been loaded into memory at some point. The objective is to verify that this information is exposed as briefly as possible.\n\nTo investigate an application's memory, you must first create a memory dump. You can also analyze the memory in real-time, e.g., via a debugger. Regardless of your approach, memory dumping is a very error-prone process in terms of verification because each dump contains the output of executed functions. You may miss executing critical scenarios. In addition, overlooking data during analysis is probable unless you know the data's footprint (either the exact value or the data format). For example, if the app encrypts with a randomly generated symmetric key, you likely won't be able to spot it in memory unless you can recognize the key's value in another context.\n\nTherefore, you are better off starting with static analysis."
  },
  {
    "id": "MASTG-TEST-0012",
    "title": "Mobile Security Test 0012",
    "category": "Android Security Testing",
    "description": "Apps that process or query sensitive information should run in a trusted and secure environment. To create this environment, the app can check the device for the following:",
    "full_description": "Apps that process or query sensitive information should run in a trusted and secure environment. To create this environment, the app can check the device for the following:\n\n- PIN- or password-protected device locking\n- Recent Android OS version\n- USB Debugging activation\n- Device encryption\n- Device rooting (see also \"Testing Root Detection\")"
  },
  {
    "id": "MASTG-TEST-0064",
    "title": "Mobile Security Test 0064",
    "category": "iOS Security Testing",
    "description": "The usage of frameworks in an app can be detected by analyzing the app binary's list of shared dynamic libraries. This can be done by using @MASTG-TOOL-0060:",
    "full_description": "The usage of frameworks in an app can be detected by analyzing the app binary's list of shared dynamic libraries. This can be done by using @MASTG-TOOL-0060:\n\n```bash\notool -L <AppName>.app/<AppName>\n```\n\nIf `LocalAuthentication.framework` is used in an app, the output will contain both of the following lines (remember that `LocalAuthentication.framework` uses `Security.framework` under the hood):\n\n```bash\n/System/Library/Frameworks/LocalAuthentication.framework/LocalAuthentication\n/System/Library/Frameworks/Security.framework/Security\n```\n\nIf `Security.framework` is used, only the second one will be shown."
  },
  {
    "id": "MASTG-TEST-0079",
    "title": "Mobile Security Test 0079",
    "category": "iOS Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\nAll different flavors of object persistence share the following concerns:\n\n- If you use object persistence to store sensitive information on the device, then make sure that the data is encrypted: either at the database level, or specifically at the value level.\n- Need to guarantee the integrity of the information? Use an HMAC mechanism or sign the information stored. Always verify the HMAC/signature before processing the actual information stored in the objects.\n- Make sure that keys used in the two notions above are safely stored in the KeyChain and well protected. See the chapter \"[Data Storage on iOS](../../../Document/0x06d-Testing-Data-Storage.md)\" for more details.\n- Ensure that the data within the deserialized object is carefully validated before it is actively used (e.g., no exploit of business/application logic is possible).\n- Do not use persistence mechanisms that use [Runtime Reference](https://developer.apple.com/documentation/objectivec/objective-c_runtime \"Objective-C Runtime Reference\") to serialize/deserialize objects in high-risk applications, as the attacker might be able to manipulate the steps to execute business logic via this mechanism (see the chapter \"[iOS Anti-Reversing Defenses](../../../Document/0x06j-Testing-Resiliency-Against-Reverse-Engineering.md)\" for more details).\n- Note that in Swift 2 and beyond, a [Mirror](https://developer.apple.com/documentation/swift/mirror \"Mirror\") can be used to read parts of an object, but cannot be used to write against the object."
  },
  {
    "id": "MASTG-TEST-0080",
    "title": "Mobile Security Test 0080",
    "category": "iOS Security Testing",
    "description": "Mobile application security test as per OWASP MASTG guidelines.",
    "full_description": "Mobile application security test as per OWASP MASTG guidelines."
  },
  {
    "id": "MASTG-TEST-0085",
    "title": "Mobile Security Test 0085",
    "category": "iOS Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\n### Detecting vulnerabilities of third party libraries\n\nIn order to ensure that the libraries used by the apps are not carrying vulnerabilities, one can best check the dependencies installed by CocoaPods or Carthage.\n\n#### Swift Package Manager\n\nIn case [Swift Package Manager](https://swift.org/package-manager \"Swift Package Manager on Swift.org\") is used for managing third party dependencies, the following steps can be taken to analyze the third party libraries for vulnerabilities:\n\nFirst, at the root of the project, where the Package.swift file is located, type\n\n```bash\nswift build\n```\n\nNext, check the file Package.resolved for the actual versions used and inspect the given libraries for known vulnerabilities.\n\nYou can utilize the [OWASP Dependency-Check](https://owasp.org/www-project-dependency-check/ \"OWASP Dependency-Check\")'s experimental [Swift Package Manager Analyzer](https://jeremylong.github.io/DependencyCheck/analyzers/swift.html \"dependency-check - SWIFT Package Manager Analyzer\") to identify the [Common Platform Enumeration (CPE)](https://nvd.nist.gov/products/cpe \"CPE\") naming scheme of all dependencies and any corresponding [Common Vulnerability and Exposure (CVE)](https://cve.mitre.org/ \"CVE\") entries. Scan the application's Package.swift file and generate a report of known vulnerable libraries with the following command:\n\n```bash\ndependency-check  --enableExperimental --out . --scan Package.swift\n```\n\n#### CocoaPods\n\nIn case [CocoaPods](https://cocoapods.org \"CocoaPods.org\") is used for managing third party dependencies, the following steps can be taken to analyze the third party libraries for vulnerabilities.\n\nFirst, at the root of the project, where the Podfile is located, execute the following commands:\n\n```bash\nsudo gem install cocoapods\npod install\n```\n\nNext, now that the dependency tree has been built, you can create an overview of the dependencies and their versions by running the following commands:\n\n```bash\nsudo gem install cocoapods-dependencies\npod dependencies\n```\n\nThe result of the steps above can now be used as input for searching different vulnerability feeds for known vulnerabilities.\n\n> Note:\n>\n> 1. If the developer packs all dependencies in terms of its own support library using a .podspec file, then this .podspec file can be checked with the experimental CocoaPods podspec checker.\n> 2. If the project uses CocoaPods in combination with Objective-C, SourceClear can be used.\n> 3. Using CocoaPods with HTTP-based links instead of HTTPS might allow for [Machine-in-the-Middle (MITM)](../../../Document/0x04f-Testing-Network-Communication.md#intercepting-network-traffic-through-mitm) attacks during the download of the dependency, allowing an attacker to replace (parts of) the library with other content. Therefore, always use HTTPS.\n\nYou can utilize the [OWASP Dependency-Check](https://owasp.org/www-project-dependency-check/ \"OWASP Dependency-Check\")'s experimental [CocoaPods Analyzer](https://jeremylong.github.io/DependencyCheck/analyzers/cocoapods.html \"dependency-check - CocoaPods Analyzer\")\nto identify the [Common Platform Enumeration (CPE)](https://nvd.nist.gov/products/cpe \"CPE\") naming scheme of all dependencies and any corresponding [Common Vulnerability and Exposure (CVE)](https://cve.mitre.org/ \"CVE\") entries. Scan the application's \\*.podspec and/or Podfile.lock files and generate a report of known vulnerable libraries with the following command:\n\n```bash\ndependency-check  --enableExperimental --out . --scan Podfile.lock\n```\n\n#### Carthage\n\nIn case [Carthage](https://github.com/Carthage/Carthage \"Carthage on GitHub\") is used for third party dependencies, then the following steps can be taken to analyze the third party libraries for vulnerabilities.\n\nFirst, at the root of the project, where the Cartfile is located, type\n\n```bash\nbrew install carthage\ncarthage update --platform iOS\n```\n\nNext, check the Cartfile.resolved for actual versions used and inspect the given libraries for known vulnerabilities.\n\n> Note, at the time of writing this chapter, there is no automated support for Carthage based dependency analysis known to the authors. At least, this feature was already requested for the OWASP DependencyCheck tool but not yet implemented (see the [GitHub issue](https://github.com/jeremylong/DependencyCheck/issues/962 \"Add Carthage Analyze for Swift\")).\n\n### Discovered library vulnerabilities\n\nWhen a library is found to contain vulnerabilities, then the following reasoning applies:\n\n- Is the library packaged with the application? Then check whether the library has a version in which the vulnerability is patched. If not, check whether the vulnerability actually affects the application. If that is the case or might be the case in the future, then look for an alternative which provides similar functionality, but without the vulnerabilities.\n- Is the library not packaged with the application? See if there is a patched version in which the vulnerability is fixed. If this is not the case, check if the implications of the vulnerability for the build process. Could the vulnerability impede a build or weaken the security of the build-pipeline? Then try looking for an alternative in which the vulnerability is fixed.\n\nIn case frameworks are added manually as linked libraries:\n\n1. Open the xcodeproj file and check the project properties.\n2. Go to the tab **Build Phases** and check the entries in **Link Binary With Libraries** for any of the libraries. See earlier sections on how to obtain similar information using @MASTG-TOOL-0035.\n\nIn the case of copy-pasted sources: search the header files (in case of using Objective-C) and otherwise the Swift files for known method names for known libraries.\n\nNext, note that for hybrid applications, you will have to check the JavaScript dependencies with [RetireJS](https://retirejs.github.io/retire.js/ \"RetireJS\"). Similarly for Xamarin, you will have to check the C# dependencies.\n\nLast, if the application is a high-risk application, you will end up vetting the library manually. In that case there are specific requirements for native code, which are similar to the requirements established by the MASVS for the application as a whole. Next to that, it is good to vet whether all best practices for software engineering are applied."
  },
  {
    "id": "MASTG-TEST-0086",
    "title": "Mobile Security Test 0086",
    "category": "iOS Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\nAre there native code parts? If so: check for the given issues in the general memory corruption section. Native code is a little harder to spot when compiled. If you have the sources then you can see that C files use .c source files and .h header files and C++ uses .cpp files and .h files. This is a little different from the .swift and the .m source files for Swift and Objective-C. These files can be part of the sources, or part of third party libraries, registered as frameworks and imported through various tools, such as Carthage, the Swift Package Manager or Cocoapods.\n\nFor any managed code (Objective-C / Swift) in the project, check the following items:\n\n- The doubleFree issue: when `free` is called twice for a given region instead of once.\n- Retaining cycles: look for cyclic dependencies by means of strong references of components to one another which keep materials in memory.\n- Using instances of `UnsafePointer` can be managed wrongly, which will allow for various memory corruption issues.\n- Trying to manage the reference count to an object by `Unmanaged` manually, leading to wrong counter numbers and a too late/too soon release.\n\n[A great talk is given on this subject at Realm academy](https://academy.realm.io/posts/russ-bishop-unsafe-swift/ \"Russh Bishop on Unsafe Swift\") and [a nice tutorial to see what is actually happening](https://www.raywenderlich.com/780-unsafe-swift-using-pointers-and-interacting-with-c \"Unsafe Swift: Using Pointers And Interacting With C\") is provided by Ray Wenderlich on this subject.\n\n> Please note that with Swift 5 you can only deallocate full blocks, which means the playground has changed a bit."
  },
  {
    "id": "MASTG-TEST-0087",
    "title": "Mobile Security Test 0087",
    "category": "iOS Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\nYou can use radare2 to check the binary security features.\n\nLet's use the [Damn Vulnerable iOS App DVIA v1](https://github.com/prateek147/DVIA/) as an example. Open its main binary with radare2:\n\n```bash\nr2 DamnVulnerableIOSApp\n```\n\nAnd run the following commands:\n\n```bash\n[0x1000180c8]> i~pic,canary\ncanary   true\npic      true\n```\n\n```bash\n[0x1000180c8]> is~release,retain\n124  0x002951e0 0x1000891e0 LOCAL  FUNC 0        imp.dispatch_release\n149  0x00294e80 0x100088e80 LOCAL  FUNC 0        imp.objc_autorelease\n150  0x00294e8c 0x100088e8c LOCAL  FUNC 0        imp.objc_autoreleasePoolPop\n151  0x00294e98 0x100088e98 LOCAL  FUNC 0        imp.objc_autoreleasePoolPush\n152  0x00294ea4 0x100088ea4 LOCAL  FUNC 0        imp.objc_autoreleaseReturnValue\n165  0x00294f40 0x100088f40 LOCAL  FUNC 0        imp.objc_release\n167  0x00294f58 0x100088f58 LOCAL  FUNC 0        imp.objc_retainAutorelease\n168  0x00294f64 0x100088f64 LOCAL  FUNC 0        imp.objc_retainAutoreleaseReturnValue\n169  0x00294f70 0x100088f70 LOCAL  FUNC 0        imp.objc_retainAutoreleasedReturnValue\n```\n\nAll the features are enabled in these examples:\n\n- PIE (Position Independent Executable): indicated by the flag `pic true`.\n    - Applies to all apps independently of the language used.\n    - Applies only to the main executable (`MH_EXECUTE`), not to dynamic libraries (`MH_DYLIB`).\n\n- Stack Canary: indicated by the flag `canary true`.\n    - Applies to apps containing Objective-C code.\n    - Not necessarily required for pure Swift apps (Swift is memory safe by design).\n    - Especially important for apps containing C/C++ code, as they provide direct access to memory and pointers, making them more vulnerable to buffer overflows.\n\n- ARC (Automatic Reference Counting): indicated by symbols such as `objc_autorelease` or `objc_retainAutorelease`.\n    - Important for binaries containing Objective-C code.\n    - For binaries written purely in Swift, ARC is enabled by default.\n    - ARC is not relevant for binaries written purely in C/C++, as it's a memory management feature specific to Objective-C and Swift."
  },
  {
    "id": "MASTG-TEST-0061",
    "title": "Mobile Security Test 0061",
    "category": "iOS Security Testing",
    "description": "Mobile application security test as per OWASP MASTG guidelines.",
    "full_description": "Mobile application security test as per OWASP MASTG guidelines."
  },
  {
    "id": "MASTG-TEST-0062",
    "title": "Mobile Security Test 0062",
    "category": "iOS Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\nThere are various keywords to look for: check the libraries mentioned in the overview and static analysis of the section \"Verifying the Configuration of Cryptographic Standard Algorithms\" for which keywords you can best check on how keys are stored.\n\nAlways make sure that:\n\n- keys are not synchronized over devices if it is used to protect high-risk data.\n- keys are not stored without additional protection.\n- keys are not hardcoded.\n- keys are not derived from stable features of the device.\n- keys are not hidden by use of lower level languages (e.g. C/C++).\n- keys are not imported from unsafe locations.\n\nCheck also the [list of common cryptographic configuration issues](../../../Document/0x04g-Testing-Cryptography.md#common-configuration-issues).\n\nMost of the recommendations for static analysis can already be found in chapter \"Testing Data Storage for iOS\". Next, you can read up on it at the following pages:\n\n- [Apple Developer Documentation: Certificates and keys](https://developer.apple.com/documentation/security/certificate_key_and_trust_services/keys \"Certificates and keys\")\n- [Apple Developer Documentation: Generating new keys](https://developer.apple.com/documentation/security/certificate_key_and_trust_services/keys/generating_new_cryptographic_keys \"Generating new keys\")\n- [Apple Developer Documentation: Key generation attributes](https://developer.apple.com/documentation/security/certificate_key_and_trust_services/keys/key_generation_attributes \"Key Generation attributes\")"
  },
  {
    "id": "MASTG-TEST-0063",
    "title": "Mobile Security Test 0063",
    "category": "iOS Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\nIn Swift, the [`SecRandomCopyBytes` API](https://developer.apple.com/reference/security/1399291-secrandomcopybytes \"SecRandomCopyBytes (Swift)\") is defined as follows:\n\n```default\nfunc SecRandomCopyBytes(_ rnd: SecRandomRef?,\n                      _ count: Int,\n                      _ bytes: UnsafeMutablePointer<UInt8>) -> Int32\n```\n\nThe [Objective-C version](https://developer.apple.com/reference/security/1399291-secrandomcopybytes?language=objc \"SecRandomCopyBytes (Objective-C)\") is\n\n```objectivec\nint SecRandomCopyBytes(SecRandomRef rnd, size_t count, uint8_t *bytes);\n```\n\nThe following is an example of the APIs usage:\n\n```objectivec\nint result = SecRandomCopyBytes(kSecRandomDefault, 16, randomBytes);\n```\n\nNote: if other mechanisms are used for random numbers in the code, verify that these are either wrappers around the APIs mentioned above or review them for their secure-randomness. Often this is too hard, which means you can best stick with the implementation above."
  },
  {
    "id": "MASTG-TEST-0065",
    "title": "Mobile Security Test 0065",
    "category": "iOS Security Testing",
    "description": "All the presented cases must be carefully analyzed as a whole. For example, even if the app does not permit cleartext traffic in its Info.plist, it might actually still be sending HTTP traffic. That c...",
    "full_description": "All the presented cases must be carefully analyzed as a whole. For example, even if the app does not permit cleartext traffic in its Info.plist, it might actually still be sending HTTP traffic. That could be the case if it's using a low-level API (for which ATS is ignored) or a badly configured cross-platform framework.\n\n> IMPORTANT: You should apply these tests to the app main code but also to any app extensions, frameworks or Watch apps embedded within the app as well.\n\nFor more information refer to the article [\"Preventing Insecure Network Connections\"](https://developer.apple.com/documentation/security/preventing_insecure_network_connections) and [\"Fine-tune your App Transport Security settings\"](https://developer.apple.com/news/?id=jxky8h89) in the Apple Developer Documentation."
  },
  {
    "id": "MASTG-TEST-0066",
    "title": "Mobile Security Test 0066",
    "category": "iOS Security Testing",
    "description": "Remember to [inspect the corresponding justifications](https://developer.apple.com/documentation/security/preventing_insecure_network_connections#3138036) to discard that it might be part of the app i...",
    "full_description": "Remember to [inspect the corresponding justifications](https://developer.apple.com/documentation/security/preventing_insecure_network_connections#3138036) to discard that it might be part of the app intended purpose.\n\nIt is possible to verify which ATS settings can be used when communicating to a certain endpoint. On macOS the command line utility `nscurl` can be used. A permutation of different settings will be executed and verified against the specified endpoint. If the default ATS secure connection test is passing, ATS can be used in its default secure configuration. If there are any fails in the nscurl output, please change the server side configuration of TLS to make the server side more secure, rather than weakening the configuration in ATS on the client. See the article \"Identifying the Source of Blocked Connections\" in the [Apple Developer Documentation](https://developer.apple.com/documentation/security/preventing_insecure_network_connections/identifying_the_source_of_blocked_connections) for more details.\n\nRefer to section \"Verifying the TLS Settings\" in chapter [Testing Network Communication](../../../Document/0x04f-Testing-Network-Communication.md#verifying-the-tls-settings) for details."
  },
  {
    "id": "MASTG-TEST-0067",
    "title": "Mobile Security Test 0067",
    "category": "iOS Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\nUsing TLS to transport sensitive information over the network is essential for security. However, encrypting communication between a mobile application and its backend API is not trivial. Developers often decide on simpler but less secure solutions (e.g., those that accept any certificate) to facilitate the development process, and sometimes these weak solutions make it into the production version, potentially exposing users to [Machine-in-the-Middle (MITM)](../../../Document/0x04f-Testing-Network-Communication.md#intercepting-network-traffic-through-mitm) attacks. See [\"CWE-295: Improper Certificate Validation\"](https://cwe.mitre.org/data/definitions/295.html \"CWE-295: Improper Certificate Validation\").\n\nThese are some of the issues should be addressed:\n\n- Check if the app links against an SDK older than iOS 9.0. In that case ATS is disabled no matter which version of the OS the app runs on.\n- Verify that a certificate comes from a trusted source, i.e. a trusted CA (Certificate Authority).\n- Determine whether the endpoint server presents the right certificate.\n\nMake sure that the hostname and the certificate itself are verified correctly. Examples and common pitfalls are available in the [official Apple documentation](https://developer.apple.com/documentation/security/preventing_insecure_network_connections \"Preventing Insecure Network Connections\").\n\nWe highly recommend supporting static analysis with the dynamic analysis. If you don't have the source code or the app is difficult to reverse engineer, having a solid dynamic analysis strategy can definitely help. In that case you won't know if the app uses low or high-level APIs but you can still test for different trust evaluation scenarios (e.g. \"does the app accept a self-signed certificate?\")."
  },
  {
    "id": "MASTG-TEST-0068",
    "title": "Mobile Security Test 0068",
    "category": "iOS Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\nVerify that the server certificate is pinned. Pinning can be implemented on various levels in terms of the certificate tree presented by the server:\n\n1. Including server's certificate in the application bundle and performing verification on each connection. This requires an update mechanisms whenever the certificate on the server is updated.\n2. Limiting certificate issuer to e.g. one entity and bundling the intermediate CA's public key into the application. In this way we limit the attack surface and have a valid certificate.\n3. Owning and managing your own PKI. The application would contain the intermediate CA's public key. This avoids updating the application every time you change the certificate on the server, due to e.g. expiration. Note that using your own CA would cause the certificate to be self-singed.\n\nThe latest approach recommended by Apple is to specify a pinned CA public key in the `Info.plist` file under App Transport Security Settings. You can find an example in their article [Identity Pinning: How to configure server certificates for your app](https://developer.apple.com/news/?id=g9ejcf8y \"Identity Pinning: How to configure server certificates for your app\").\n\nAnother common approach is to use the [`connection:willSendRequestForAuthenticationChallenge:`](https://developer.apple.com/documentation/foundation/nsurlconnectiondelegate/1414078-connection?language=objc \"connection:willSendRequestForAuthenticationChallenge:\") method of `NSURLConnectionDelegate` to check if the certificate provided by the server is valid and matches the certificate stored in the app. You can find more details in the [HTTPS Server Trust Evaluation](https://developer.apple.com/library/archive/technotes/tn2232/_index.html#//apple_ref/doc/uid/DTS40012884-CH1-SECNSURLCONNECTION \"HTTPS Server Trust Evaluation\") technical note.\n\nThe following third-party libraries include pinning functionality:\n\n- [TrustKit](https://github.com/datatheorem/TrustKit \"TrustKit\"): here you can pin by setting the public key hashes in your Info.plist or provide the hashes in a dictionary. See their README for more details.\n- [AlamoFire](https://github.com/Alamofire/Alamofire \"AlamoFire\"): here you can define a `ServerTrustPolicy` per domain for which you can define a `PinnedCertificatesTrustEvaluator`. See its [documentation](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#security) for more details.\n- [AFNetworking](https://github.com/AFNetworking/AFNetworking \"AfNetworking\"): here you can set an `AFSecurityPolicy` to configure your pinning."
  },
  {
    "id": "MASTG-TEST-0056",
    "title": "Mobile Security Test 0056",
    "category": "iOS Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\nThe following section summarizes keywords that you should look for to identify IPC implementations within iOS source code.\n\n### XPC Services\n\nSeveral classes may be used to implement the NSXPCConnection API:\n\n- NSXPCConnection\n- NSXPCInterface\n- NSXPCListener\n- NSXPCListenerEndpoint\n\nYou can set [security attributes](https://www.objc.io/issues/14-mac/xpc/#security-attributes-of-the-connection \"Security Attributes of NSXPCConnection\") for the connection. The attributes should be verified.\n\nCheck for the following two files in the Xcode project for the XPC Services API (which is C-based):\n\n- [`xpc.h`](https://developer.apple.com/documentation/xpc/xpc_services_xpc.h \"xpc.h\")\n- `connection.h`\n\n### Mach Ports\n\nKeywords to look for in low-level implementations:\n\n- mach\\_port\\_t\n- mach\\_msg\\_*\n\nKeywords to look for in high-level implementations (Core Foundation and Foundation wrappers):\n\n- CFMachPort\n- CFMessagePort\n- NSMachPort\n- NSMessagePort\n\n### NSFileCoordinator\n\nKeywords to look for:\n\n- NSFileCoordinator"
  },
  {
    "id": "MASTG-TEST-0057",
    "title": "Mobile Security Test 0057",
    "category": "iOS Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\nA text field that masks its input can be configured in two ways:\n\n**Storyboard**\nIn the iOS project's storyboard, navigate to the configuration options for the text field that takes sensitive data. Make sure that the option \"Secure Text Entry\" is selected. If this option is activated, dots are shown in the text field in place of the text input.\n\n**Source Code**\nIf the text field is defined in the source code, make sure that the option [`isSecureTextEntry`](https://developer.apple.com/documentation/uikit/uitextinputtraits/1624427-issecuretextentry \"isSecureTextEntry in Text Field\") is set to \"true\". This option obscures the text input by showing dots.\n\n```swift\nsensitiveTextField.isSecureTextEntry = true\n```"
  },
  {
    "id": "MASTG-TEST-0059",
    "title": "Mobile Security Test 0059",
    "category": "iOS Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\nIf you have the source code, search for the [`applicationDidEnterBackground`](https://developer.apple.com/documentation/uikit/uiapplicationdelegate/1622997-applicationdidenterbackground) method to determine whether the application sanitizes the screen before being backgrounded.\n\nThe following is a sample implementation using a default background image (`overlayImage.png`) whenever the application is backgrounded, overriding the current view:\n\nSwift:\n\n```swift\nprivate var backgroundImage: UIImageView?\n\nfunc applicationDidEnterBackground(_ application: UIApplication) {\n    let myBanner = UIImageView(image: #imageLiteral(resourceName: \"overlayImage\"))\n    myBanner.frame = UIScreen.main.bounds\n    backgroundImage = myBanner\n    window?.addSubview(myBanner)\n}\n\nfunc applicationWillEnterForeground(_ application: UIApplication) {\n    backgroundImage?.removeFromSuperview()\n}\n```\n\nObjective-C:\n\n```objectivec\n@property (UIImageView *)backgroundImage;\n\n- (void)applicationDidEnterBackground:(UIApplication *)application {\n    UIImageView *myBanner = [[UIImageView alloc] initWithImage:@\"overlayImage.png\"];\n    self.backgroundImage = myBanner;\n    self.backgroundImage.bounds = UIScreen.mainScreen.bounds;\n    [self.window addSubview:myBanner];\n}\n\n- (void)applicationWillEnterForeground:(UIApplication *)application {\n    [self.backgroundImage removeFromSuperview];\n}\n```\n\nThis sets the background image to `overlayImage.png` whenever the application is backgrounded. It prevents sensitive data leaks because `overlayImage.png` will always override the current view."
  },
  {
    "id": "MASTG-TEST-0069",
    "title": "Mobile Security Test 0069",
    "category": "iOS Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\nSince iOS 10, these are the main areas which you need to inspect for permissions:\n\n- Purpose Strings in the Info.plist File\n- Code Signing Entitlements File\n- Embedded Provisioning Profile File\n- Entitlements Embedded in the Compiled App Binary\n- Usage of Permissions in Source Code\n\n### Purpose Strings in the Info.plist File\n\nIf having the original source code, you can verify the permissions included in the `Info.plist` file:\n\n- Open the project with Xcode.\n- Find and open the `Info.plist` file in the default editor and search for the keys starting with `\"Privacy -\"`.\n\nYou may switch the view to display the raw values by right-clicking and selecting \"Show Raw Keys/Values\" (this way for example `\"Privacy - Location When In Use Usage Description\"` will turn into `NSLocationWhenInUseUsageDescription`).\n\n<img src=\"Images/Chapters/0x06h/purpose_strings_xcode.png\" width=\"100%\" />\n\nIf only having the IPA:\n\n- Unzip the IPA.\n- The `Info.plist` is located in `Payload/<appname>.app/Info.plist`.\n- Convert it if needed (e.g. `plutil -convert xml1 Info.plist`) as explained in the chapter \"iOS Basic Security Testing\", section \"The Info.plist File\".\n- Inspect all _purpose strings Info.plist keys_, usually ending with `UsageDescription`:\n\n    ```xml\n    <plist version=\"1.0\">\n    <dict>\n        <key>NSLocationWhenInUseUsageDescription</key>\n        <string>Your location is used to provide turn-by-turn directions to your destination.</string>\n    ```\n\nFor each purpose string in the `Info.plist` file, check if the permission makes sense.\n\nFor example, imagine the following lines were extracted from a `Info.plist` file used by a Solitaire game:\n\n```xml\n<key>NSHealthClinicalHealthRecordsShareUsageDescription</key>\n<string>Share your health data with us!</string>\n<key>NSCameraUsageDescription</key>\n<string>We want to access your camera</string>\n```\n\nIt should be suspicious that a regular solitaire game requests this kind of resource access as it probably does not have any need for [accessing the camera](https://developer.apple.com/library/archive/documentation/General/Reference/InfoPlistKeyReference/Articles/CocoaKeys.html#//apple_ref/doc/uid/TP40009251-SW24 \"NSCameraUsageDescription\") nor a [user's health-records](https://developer.apple.com/library/archive/documentation/General/Reference/InfoPlistKeyReference/Articles/CocoaKeys.html#//apple_ref/doc/uid/TP40009251-SW76 \"NSHealthClinicalHealthRecordsShareUsageDescription\").\n\nApart from simply checking if the permissions make sense, further analysis steps might be derived from analyzing purpose strings e.g. if they are related to storage sensitive data. For example, `NSPhotoLibraryUsageDescription` can be considered as a storage permission giving access to files that are outside of the app's sandbox and might also be accessible by other apps. In this case, it should be tested that no sensitive data is being stored there (photos in this case). For other purpose strings like `NSLocationAlwaysUsageDescription`, it must be also considered if the app is storing this data securely. Refer to the \"Testing Data Storage\" chapter for more information and best practices on securely storing sensitive data.\n\n### Embedded Provisioning Profile File\n\nWhen you do not have the original source code, you should analyze the IPA and search inside for the _embedded provisioning profile_ that is usually located in the root app bundle folder (`Payload/<appname>.app/`) under the name `embedded.mobileprovision`.\n\nThis file is not a `.plist`, it is encoded using [Cryptographic Message Syntax](https://en.wikipedia.org/wiki/Cryptographic_Message_Syntax \"Cryptographic Message Syntax\"). On macOS you can [inspect an embedded provisioning profile's entitlements](https://developer.apple.com/library/archive/technotes/tn2415/_index.html#//apple_ref/doc/uid/DTS40016427-CH1-PROFILESENTITLEMENTS \"Inspecting a profile\\'s entitlements\") using the following command:\n\n```bash\nsecurity cms -D -i embedded.mobileprovision\n```\n\nand then search for the Entitlements key region (`<key>Entitlements</key>`).\n\n### Entitlements Embedded in the Compiled App Binary\n\nIf you only have the app's IPA or simply the installed app on a jailbroken device, you normally won't be able to find `.entitlements` files. This could also be the case for the `embedded.mobileprovision` file. Still, you should be able to extract the entitlements property lists from the app binary yourself (see @MASTG-TECH-0111).\n\n### Usage of Permissions in Source Code\n\nAfter having checked the `<appname>.entitlements` file and the `Info.plist` file, it is time to verify how the requested permissions and assigned capabilities are put to use. For this, a source code review should be enough. However, if you don't have the original source code, verifying the use of permissions might be specially challenging as you might need to reverse engineer the app, refer to the \"Dynamic Analysis\" for more details on how to proceed.\n\nWhen doing a source code review, pay attention to:\n\n- whether the _purpose strings_ in the `Info.plist` file match the programmatic implementations.\n- whether the registered capabilities are used in such a way that no confidential information is leaking.\n\nUsers can grant or revoke authorization at any time via \"Settings\", therefore apps normally check the authorization status of a feature before accessing it. This can be done by using dedicated APIs available for many system frameworks that provide access to protected resources.\n\nYou can use the [Apple Developer Documentation](https://developer.apple.com/documentation/uikit/core_app/protecting_the_user_s_privacy/accessing_protected_resources?language=objc#3037319 \"Check for Authorization\") as a starting point. For example:\n\n- Bluetooth: the [`state`](https://developer.apple.com/documentation/corebluetooth/cbmanager/1648600-state?language=objc \"CBManager state\") property of the [`CBCentralManager`](https://developer.apple.com/documentation/corebluetooth/cbcentralmanager?language=objc \"CBCentralManager\") class is used to check system-authorization status for using Bluetooth peripherals.\n- Location: search for methods of `CLLocationManager`, e.g. [`locationServicesEnabled`](https://developer.apple.com/documentation/corelocation/cllocationmanager/1423648-locationservicesenabled?language=objc \"CLLocationManager locationServicesEnabled\").\n\n    ```default\n    func checkForLocationServices() {\n        if CLLocationManager.locationServicesEnabled() {\n            // Location services are available, so query the users location.\n        } else {\n            // Update your apps UI to show that the location is unavailable.\n        }\n    }\n    ```\n\n    See Table1 in [\"Determining the Availability of Location Services\"](https://developer.apple.com/documentation/corelocation/adding_location_services_to_your_app \"Getting the availability of Core Location services\") (Apple Developer Documentation) for a complete list.\n\nGo through the application searching for usages of these APIs and check what happens to sensitive data that might be obtained from them. For example, it might be stored or transmitted over the network, if this is the case, proper data protection and transport security should be additionally verified."
  },
  {
    "id": "MASTG-TEST-0070",
    "title": "Mobile Security Test 0070",
    "category": "iOS Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\nTesting universal links on a static approach includes doing the following:\n\n- Checking the Associated Domains entitlement\n- Retrieving the Apple App Site Association file\n- Checking the link receiver method\n- Checking the data handler method\n- Checking if the app is calling other app's universal links\n\n### Checking the Associated Domains Entitlement\n\nUniversal links require the developer to add the Associated Domains entitlement and include in it a list of the domains that the app supports.\n\nIn Xcode, go to the **Capabilities** tab and search for **Associated Domains**. You can also inspect the `.entitlements` file looking for `com.apple.developer.associated-domains`. Each of the domains must be prefixed with `applinks:`, such as `applinks:www.mywebsite.com`.\n\nHere's an example from Telegram's `.entitlements` file:\n\n```xml\n    <key>com.apple.developer.associated-domains</key>\n    <array>\n        <string>applinks:telegram.me</string>\n        <string>applinks:t.me</string>\n    </array>\n```\n\nMore detailed information can be found in the [archived Apple Developer Documentation](https://developer.apple.com/library/archive/documentation/General/Conceptual/AppSearch/UniversalLinks.html#//apple_ref/doc/uid/TP40016308-CH12-SW2 \"Preparing Your App to Handle Universal Links\").\n\nIf you don't have the original source code you can extract them from the MachO file as explained in @MASTG-TECH-0111.\n\n### Retrieving the Apple App Site Association File\n\nTry to retrieve the `apple-app-site-association` file from the server using the associated domains you got from the previous step. This file needs to be accessible via HTTPS, without any redirects, at `https://<domain>/apple-app-site-association` or `https://<domain>/.well-known/apple-app-site-association`.\n\nYou can retrieve it yourself using your browser and navigating to `https://<domain>/apple-app-site-association`, `https://<domain>/.well-known/apple-app-site-association` or using Apple's CDN at `https://app-site-association.cdn-apple.com/a/v1/<domain>`.\n\nAlternatively, you can use the [Apple App Site Association (AASA) Validator](https://branch.io/resources/aasa-validator/ \"AASA\"). After entering the domain, it will display the file, verify it for you and show the results (e.g. if it is not being properly served over HTTPS). See the following example from apple.com `https://www.apple.com/.well-known/apple-app-site-association`:\n\n<img src=\"Images/Chapters/0x06h/apple-app-site-association-file_validation.png\" width=\"100%\" />\n\n```json\n{\n    \"activitycontinuation\": {\n    \"apps\": [\n        \"W74U47NE8E.com.apple.store.Jolly\"\n    ]\n    },\n    \"applinks\": {\n        \"apps\": [],\n        \"details\": [\n            {\n            \"appID\": \"W74U47NE8E.com.apple.store.Jolly\",\n            \"paths\": [\n                \"NOT /shop/buy-iphone/*\",\n                \"NOT /us/shop/buy-iphone/*\",\n                \"/xc/*\",\n                \"/shop/buy-*\",\n                \"/shop/product/*\",\n                \"/shop/bag/shared_bag/*\",\n                \"/shop/order/list\",\n                \"/today\",\n                \"/shop/watch/watch-accessories\",\n                \"/shop/watch/watch-accessories/*\",\n                \"/shop/watch/bands\",\n            ] } ] }\n}\n```\n\nThe \"details\" key inside \"applinks\" contains a JSON representation of an array that might contain one or more apps. The \"appID\" should match the \"application-identifier\" key from the app's entitlements. Next, using the \"paths\" key, the developers can specify certain paths to be handled on a per app basis. Some apps, like Telegram use a standalone * (`\"paths\": [\"*\"]`) in order to allow all possible paths. Only if specific areas of the website should **not** be handled by some app, the developer can restrict access by excluding them by prepending a `\"NOT \"` (note the whitespace after the T) to the corresponding path. Also remember that the system will look for matches by following the order of the dictionaries in the array (first match wins).\n\nThis path exclusion mechanism is not to be seen as a security feature but rather as a filter that developer might use to specify which apps open which links. By default, iOS does not open any unverified links.\n\nRemember that universal links verification occurs at installation time. iOS retrieves the AASA file for the declared domains (`applinks`) in its `com.apple.developer.associated-domains` entitlement. iOS will refuse to open those links if the verification did not succeed. Some reasons to fail verification might include:\n\n- The AASA file is not served over HTTPS.\n- The AASA is not available.\n- The `appID`s do not match (this would be the case of a _malicious_ app). iOS would successfully prevent any possible hijacking attacks.\n\n### Checking the Link Receiver Method\n\nIn order to receive links and handle them appropriately, the app delegate has to implement [`application:continueUserActivity:restorationHandler:`](https://developer.apple.com/documentation/uikit/uiapplicationdelegate/1623072-application \"UIApplicationDelegate application:continueUserActivity:restorationHandler:\"). If you have the original project try searching for this method.\n\nPlease note that if the app uses [`openURL:options:completionHandler:`](https://developer.apple.com/documentation/uikit/uiapplication/1648685-openurl?language=objc \"UIApplication openURL:options:completionHandler:\") to open a universal link to the app's website, the link won't open in the app. As the call originates from the app, it won't be handled as a universal link.\n\n> From Apple Docs: When iOS launches your app after a user taps a universal link, you receive an `NSUserActivity` object with an `activityType` value of `NSUserActivityTypeBrowsingWeb`. The activity object's `webpageURL` property contains the URL that the user is accessing. The webpage URL property always contains an HTTP or HTTPS URL, and you can use `NSURLComponents` APIs to manipulate the components of the URL. [...] To protect users' privacy and security, you should not use HTTP when you need to transport data; instead, use a secure transport protocol such as HTTPS.\n\nFrom the note above we can highlight that:\n\n- The mentioned `NSUserActivity` object comes from the `continueUserActivity` parameter, as seen in the method above.\n- The scheme of the `webpageURL` must be HTTP or HTTPS (any other scheme should throw an exception). The [`scheme` instance property](https://developer.apple.com/documentation/foundation/urlcomponents/1779624-scheme \"URLComponents scheme\") of `URLComponents` / `NSURLComponents` can be used to verify this.\n\nIf you don't have the original source code you can use @MASTG-TOOL-0073 or @MASTG-TOOL-0129 to search the binary strings for the link receiver method:\n\n```bash\n$ rabin2 -zq Telegram\\ X.app/Telegram\\ X | grep restorationHan\n\n0x1000deea9 53 52 application:continueUserActivity:restorationHandler:\n```\n\n### Checking the Data Handler Method\n\nYou should check how the received data is validated. Apple [explicitly warns about this](https://developer.apple.com/documentation/uikit/core_app/allowing_apps_and_websites_to_link_to_your_content/handling_universal_links \"Handling Universal Links\"):\n\n> Universal links offer a potential attack vector into your app, so make sure to validate all URL parameters and discard any malformed URLs. In addition, limit the available actions to those that do not risk the user's data. For example, do not allow universal links to directly delete content or access sensitive information about the user. When testing your URL-handling code, make sure your test cases include improperly formatted URLs.\n\nAs stated in the [Apple Developer Documentation](https://developer.apple.com/documentation/uikit/core_app/allowing_apps_and_websites_to_link_to_your_content/handling_universal_links \"Handling Universal Links\"), when iOS opens an app as the result of a universal link, the app receives an `NSUserActivity` object with an `activityType` value of `NSUserActivityTypeBrowsingWeb`. The activity object's `webpageURL` property contains the HTTP or HTTPS URL that the user accesses. The following example in Swift verifies exactly this before opening the URL:\n\n```default\nfunc application(_ application: UIApplication, continue userActivity: NSUserActivity,\n                 restorationHandler: @escaping ([UIUserActivityRestoring]?) -> Void) -> Bool {\n    // ...\n    if userActivity.activityType == NSUserActivityTypeBrowsingWeb, let url = userActivity.webpageURL {\n        application.open(url, options: [:], completionHandler: nil)\n    }\n\n    return true\n}\n```\n\nIn addition, remember that if the URL includes parameters, they should not be trusted before being carefully sanitized and validated (even when coming from trusted domain). For example, they might have been spoofed by an attacker or might include malformed data. If that is the case, the whole URL and therefore the universal link request must be discarded.\n\nThe `NSURLComponents` API can be used to parse and manipulate the components of the URL. This can be also part of the method `application:continueUserActivity:restorationHandler:` itself or might occur on a separate method being called from it. The following [example](https://developer.apple.com/documentation/uikit/core_app/allowing_apps_and_websites_to_link_to_your_content/handling_universal_links#3001935 \"An example of handling a universal link\") demonstrates this:\n\n```default\nfunc application(_ application: UIApplication,\n                 continue userActivity: NSUserActivity,\n                 restorationHandler: @escaping ([Any]?) -> Void) -> Bool {\n    guard userActivity.activityType == NSUserActivityTypeBrowsingWeb,\n        let incomingURL = userActivity.webpageURL,\n        let components = NSURLComponents(url: incomingURL, resolvingAgainstBaseURL: true),\n        let path = components.path,\n        let params = components.queryItems else {\n        return false\n    }\n\n    if let albumName = params.first(where: { $0.name == \"albumname\" })?.value,\n        let photoIndex = params.first(where: { $0.name == \"index\" })?.value {\n        // Interact with album name and photo index\n\n        return true\n\n    } else {\n        // Handle when album and/or album name or photo index missing\n\n        return false\n    }\n}\n```\n\nFinally, as stated above, be sure to verify that the actions triggered by the URL do not expose sensitive information or risk the user's data on any way.\n\n### Checking if the App is Calling Other App's Universal Links\n\nAn app might be calling other apps via universal links in order to simply trigger some actions or to transfer information, in that case, it should be verified that it is not leaking sensitive information.\n\nIf you have the original source code, you can search it for the `openURL:options: completionHandler:` method and check the data being handled.\n\n> Note that the `openURL:options:completionHandler:` method is not only used to open universal links but also to call custom URL schemes.\n\nThis is an example from the Telegram app:\n\n```default\n}, openUniversalUrl: { url, completion in\n    if #available(iOS 10.0, *) {\n        var parsedUrl = URL(string: url)\n        if let parsed = parsedUrl {\n            if parsed.scheme == nil || parsed.scheme!.isEmpty {\n                parsedUrl = URL(string: \"https://\\(url)\")\n            }\n        }\n\n        if let parsedUrl = parsedUrl {\n            return UIApplication.shared.open(parsedUrl,\n                        options: [UIApplicationOpenURLOptionUniversalLinksOnly: true as NSNumber],\n                        completionHandler: { value in completion.completion(value)}\n            )\n```\n\nNote how the app adapts the `scheme` to \"https\" before opening it and how it uses the option `UIApplicationOpenURLOptionUniversalLinksOnly: true` that [opens the URL only if the URL is a valid universal link and there is an installed app capable of opening that URL](https://developer.apple.com/documentation/uikit/uiapplicationopenurloptionuniversallinksonly?language=objc \"UIApplicationOpenURLOptionUniversalLinksOnly\").\n\nIf you don't have the original source code, search in the symbols and in the strings of the app binary. For example, we will search for Objective-C methods that contain \"openURL\":\n\n```bash\n$ rabin2 -zq Telegram\\ X.app/Telegram\\ X | grep openURL\n\n0x1000dee3f 50 49 application:openURL:sourceApplication:annotation:\n0x1000dee71 29 28 application:openURL:options:\n0x1000df2c9 9 8 openURL:\n0x1000df772 35 34 openURL:options:completionHandler:\n```\n\nAs expected, `openURL:options:completionHandler:` is among the ones found (remember that it might be also present because the app opens custom URL schemes). Next, to ensure that no sensitive information is being leaked you'll have to perform dynamic analysis and inspect the data being transmitted. Please refer to @MASTG-TEST-0075 for some examples on hooking and tracing this method."
  },
  {
    "id": "MASTG-TEST-0071",
    "title": "Mobile Security Test 0071",
    "category": "iOS Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\n### Sending Items\n\nWhen testing `UIActivity` Sharing you should pay special attention to:\n\n- the data (items) being shared,\n- the custom activities,\n- the excluded activity types.\n\nData sharing via `UIActivity` works by creating a `UIActivityViewController` and passing it the desired items (URLs, text, a picture) on [`init(activityItems: applicationActivities:)`](https://developer.apple.com/documentation/uikit/uiactivityviewcontroller/1622019-init \"UIActivityViewController init(activityItems:applicationActivities:)\").\n\nAs we mentioned before, it is possible to exclude some of the sharing mechanisms via the controller's [`excludedActivityTypes` property](https://developer.apple.com/documentation/uikit/uiactivityviewcontroller/1622009-excludedactivitytypes \"UIActivityViewController excludedActivityTypes\"). It is highly recommended to do the tests using the latest versions of iOS as the number of activity types that can be excluded can increase. The developers have to be aware of this and **explicitly exclude** the ones that are not appropriate for the app data. Some activity types might not be even documented like \"Create Watch Face\".\n\nIf having the source code, you should take a look at the `UIActivityViewController`:\n\n- Inspect the activities passed to the `init(activityItems:applicationActivities:)` method.\n- Check if it defines custom activities (also being passed to the previous method).\n- Verify the `excludedActivityTypes`, if any.\n\nIf you only have the compiled/installed app, try searching for the previous method and property, for example using @MASTG-TOOL-0129:\n\n```bash\n$ rabin2 -zq Telegram\\ X.app/Telegram\\ X | grep -i activityItems\n0x1000df034 45 44 initWithActivityItems:applicationActivities:\n```\n\n### Receiving Items\n\nWhen receiving items, you should check:\n\n- if the app declares _custom document types_ by looking into Exported/Imported UTIs (\"Info\" tab of the Xcode project). The list of all system declared UTIs (Uniform Type Identifiers) can be found in the [archived Apple Developer Documentation](https://developer.apple.com/library/archive/documentation/Miscellaneous/Reference/UTIRef/Articles/System-DeclaredUniformTypeIdentifiers.html#//apple_ref/doc/uid/TP40009259 \"System-Declared Uniform Type Identifiers\").\n- if the app specifies any _document types that it can open_ by looking into Document Types (\"Info\" tab of the Xcode project). If present, they consist of name and one or more UTIs that represent the data type (e.g. \"public.png\" for PNG files). iOS uses this to determine if the app is eligible to open a given document (specifying Exported/Imported UTIs is not enough).\n- if the app properly _verifies the received data_ by looking into the implementation of [`application:openURL:options:`](https://developer.apple.com/documentation/uikit/uiapplicationdelegate/1623112-application?language=objc \"UIApplicationDelegate application:openURL:options:\") (or its deprecated version [`UIApplicationDelegate application:openURL:sourceApplication:annotation:`](https://developer.apple.com/documentation/uikit/uiapplicationdelegate/1623073-application?language=objc \"UIApplicationDelegate application:openURL:sourceApplication:annotation:\")) in the app delegate.\n\nIf not having the source code you can still take a look into the `Info.plist` file and search for:\n\n- `UTExportedTypeDeclarations`/`UTImportedTypeDeclarations` if the app declares exported/imported _custom document types_.\n- `CFBundleDocumentTypes` to see if the app specifies any _document types that it can open_.\n\nA very complete explanation about the use of these keys can be found [on Stackoverflow](https://stackoverflow.com/questions/21937978/what-are-utimportedtypedeclarations-and-utexportedtypedeclarations-used-for-on-i \"What are UTImportedTypeDeclarations and UTExportedTypeDeclarations used for on iOS?\").\n\nLet's see a real-world example. We will take a File Manager app and take a look at these keys. We used @MASTG-TOOL-0038 here to read the `Info.plist` file.\n\n```bash\nobjection --gadget SomeFileManager run ios plist cat Info.plist\n```\n\n> Note that this is the same as if we would retrieve the IPA from the phone or accessed via e.g. SSH and navigated to the corresponding folder in the IPA / app sandbox. However, with objection we are just _one command away_ from our goal and this can be still considered static analysis.\n\nThe first thing we noticed is that app does not declare any imported custom document types but we could find a couple of exported ones:\n\n```xml\nUTExportedTypeDeclarations =     (\n            {\n        UTTypeConformsTo =             (\n            \"public.data\"\n        );\n        UTTypeDescription = \"SomeFileManager Files\";\n        UTTypeIdentifier = \"com.some.filemanager.custom\";\n        UTTypeTagSpecification =             {\n            \"public.filename-extension\" =                 (\n                ipa,\n                deb,\n                zip,\n                rar,\n                tar,\n                gz,\n                ...\n                key,\n                pem,\n                p12,\n                cer\n            );\n        };\n    }\n);\n```\n\nThe app also declares the document types it opens as we can find the key `CFBundleDocumentTypes`:\n\n```xml\nCFBundleDocumentTypes =     (\n        {\n        ...\n        CFBundleTypeName = \"SomeFileManager Files\";\n        LSItemContentTypes =             (\n            \"public.content\",\n            \"public.data\",\n            \"public.archive\",\n            \"public.item\",\n            \"public.database\",\n            \"public.calendar-event\",\n            ...\n        );\n    }\n);\n```\n\nWe can see that this File Manager will try to open anything that conforms to any of the UTIs listed in `LSItemContentTypes` and it's ready to open files with the extensions listed in `UTTypeTagSpecification/\"public.filename-extension\"`. Please take a note of this because it will be useful if you want to search for vulnerabilities when dealing with the different types of files when performing dynamic analysis."
  },
  {
    "id": "MASTG-TEST-0072",
    "title": "Mobile Security Test 0072",
    "category": "iOS Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\nThe static analysis will take care of:\n\n- Verifying if the app contains app extensions\n- Determining the supported data types\n- Checking data sharing with the containing app\n- Verifying if the app restricts the use of app extensions\n\n### Verifying if the App Contains App Extensions\n\nIf you have the original source code you can search for all occurrences of `NSExtensionPointIdentifier` with Xcode (cmd+shift+f) or take a look into \"Build Phases / Embed App extensions\":\n\n<img src=\"Images/Chapters/0x06h/xcode_embed_app_extensions.png\" width=\"100%\" />\n\nThere you can find the names of all embedded app extensions followed by `.appex`, now you can navigate to the individual app extensions in the project.\n\nIf not having the original source code:\n\nGrep for `NSExtensionPointIdentifier` among all files inside the app bundle (IPA or installed app):\n\n```bash\n$ grep -nr NSExtensionPointIdentifier Payload/Telegram\\ X.app/\nBinary file Payload/Telegram X.app//PlugIns/SiriIntents.appex/Info.plist matches\nBinary file Payload/Telegram X.app//PlugIns/Share.appex/Info.plist matches\nBinary file Payload/Telegram X.app//PlugIns/NotificationContent.appex/Info.plist matches\nBinary file Payload/Telegram X.app//PlugIns/Widget.appex/Info.plist matches\nBinary file Payload/Telegram X.app//Watch/Watch.app/PlugIns/Watch Extension.appex/Info.plist matches\n```\n\nYou can also access per SSH, find the app bundle and list all inside PlugIns (they are placed there by default) or do it with objection:\n\n```bash\nph.telegra.Telegraph on (iPhone: 11.1.2) [usb] # cd PlugIns\n    /var/containers/Bundle/Application/15E6A58F-1CA7-44A4-A9E0-6CA85B65FA35/\n    Telegram X.app/PlugIns\n\nph.telegra.Telegraph on (iPhone: 11.1.2) [usb] # ls\nNSFileType      Perms  NSFileProtection    Read    Write     Name\n------------  -------  ------------------  ------  -------   -------------------------\nDirectory         493  None                True    False     NotificationContent.appex\nDirectory         493  None                True    False     Widget.appex\nDirectory         493  None                True    False     Share.appex\nDirectory         493  None                True    False     SiriIntents.appex\n```\n\nWe can see now the same four app extensions that we saw in Xcode before.\n\n### Determining the Supported Data Types\n\nThis is important for data being shared with host apps (e.g. via Share or Action Extensions). When the user selects some data type in a host app and it matches the data types define here, the host app will offer the extension. It is worth noticing the difference between this and data sharing via `UIActivity` where we had to define the document types, also using UTIs. An app does not need to have an extension for that. It is possible to share data using only `UIActivity`.\n\nInspect the app extension's `Info.plist` file and search for `NSExtensionActivationRule`. That key specifies the data being supported as well as e.g. maximum of items supported. For example:\n\n```xml\n<key>NSExtensionAttributes</key>\n    <dict>\n        <key>NSExtensionActivationRule</key>\n        <dict>\n            <key>NSExtensionActivationSupportsImageWithMaxCount</key>\n            <integer>10</integer>\n            <key>NSExtensionActivationSupportsMovieWithMaxCount</key>\n            <integer>1</integer>\n            <key>NSExtensionActivationSupportsWebURLWithMaxCount</key>\n            <integer>1</integer>\n        </dict>\n    </dict>\n```\n\nOnly the data types present here and not having `0` as `MaxCount` will be supported. However, more complex filtering is possible by using a so-called predicate string that will evaluate the UTIs given. Please refer to the [Apple App Extension Programming Guide](https://developer.apple.com/library/archive/documentation/General/Conceptual/ExtensibilityPG/ExtensionScenarios.html#//apple_ref/doc/uid/TP40014214-CH21-SW8 \"Declaring Supported Data Types for a Share or Action Extension\") for more detailed information about this.\n\n### Checking Data Sharing with the Containing App\n\nRemember that app extensions and their containing apps do not have direct access to each other's containers. However, data sharing can be enabled. This is done via [\"App Groups\"](https://developer.apple.com/library/archive/documentation/Miscellaneous/Reference/EntitlementKeyReference/Chapters/EnablingAppSandbox.html#//apple_ref/doc/uid/TP40011195-CH4-SW19 \"Adding an App to an App Group\") and the [`NSUserDefaults`](https://developer.apple.com/documentation/foundation/nsuserdefaults \"NSUserDefaults\") API. See this figure from [Apple App Extension Programming Guide](https://developer.apple.com/library/archive/documentation/General/Conceptual/ExtensibilityPG/ExtensionScenarios.html#//apple_ref/doc/uid/TP40014214-CH21-SW11 \"An app extension's container is distinct from its containing app's container\"):\n\n<img src=\"Images/Chapters/0x06h/app_extensions_container_restrictions.png\" width=\"400px\" />\n\nAs also mentioned in the guide, the app must set up a shared container if the app extension uses the `NSURLSession` class to perform a background upload or download, so that both the extension and its containing app can access the transferred data.\n\n### Verifying if the App Restricts the Use of App Extensions\n\nIt is possible to reject a specific type of app extension by using the following method:\n\n- [`application:shouldAllowExtensionPointIdentifier:`](https://developer.apple.com/documentation/uikit/uiapplicationdelegate/1623122-application?language=objc \"UIApplicationDelegate application:shouldAllowExtensionPointIdentifier:\")\n\nHowever, it is currently only possible for \"custom keyboard\" app extensions (and should be verified when testing apps handling sensitive data via the keyboard like e.g. banking apps)."
  },
  {
    "id": "MASTG-TEST-0073",
    "title": "Mobile Security Test 0073",
    "category": "iOS Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\nThe **systemwide general pasteboard** can be obtained by using [`generalPasteboard`](https://developer.apple.com/documentation/uikit/uipasteboard/1622106-generalpasteboard?language=objc \"UIPasteboard generalPasteboard\"), search the source code or the compiled binary for this method. Using the systemwide general pasteboard should be avoided when dealing with sensitive data.\n\n**Custom pasteboards** can be created with [`pasteboardWithName:create:`](https://developer.apple.com/documentation/uikit/uipasteboard/1622074-pasteboardwithname?language=objc \"UIPasteboard pasteboardWithName:create:\") or [`pasteboardWithUniqueName`](https://developer.apple.com/documentation/uikit/uipasteboard/1622087-pasteboardwithuniquename?language=objc \"UIPasteboard pasteboardWithUniqueName\"). Verify if custom pasteboards are set to be persistent as this is deprecated since iOS 10. A shared container should be used instead.\n\nIn addition, the following can be inspected:\n\n- Check if pasteboards are being removed with [`removePasteboardWithName:`](https://developer.apple.com/documentation/uikit/uipasteboard/1622072-removepasteboardwithname?language=objc \"UIPasteboard removePasteboardWithName:\"), which invalidates an app pasteboard, freeing up all resources used by it (no effect for the general pasteboard).\n- Check if there are excluded pasteboards, there should be a call to `setItems:options:` with the `UIPasteboardOptionLocalOnly` option.\n- Check if there are expiring pasteboards, there should be a call to `setItems:options:` with the `UIPasteboardOptionExpirationDate` option.\n- Check if the app clears the pasteboard items when going to background or when terminating. This is done by some password manager apps trying to restrict sensitive data exposure."
  },
  {
    "id": "MASTG-TEST-0075",
    "title": "Mobile Security Test 0075",
    "category": "iOS Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\nThere are a couple of things that we can do using static analysis. In the next sections we will see the following:\n\n- Testing custom URL schemes registration\n- Testing application query schemes registration\n- Testing URL handling and validation\n- Testing URL requests to other apps\n- Testing for deprecated methods\n\n### Testing Custom URL Schemes Registration\n\nThe first step to test custom URL schemes is finding out whether an application registers any protocol handlers.\n\nIf you have the original source code and want to view registered protocol handlers, simply open the project in Xcode, go to the **Info** tab and open the **URL Types** section as presented in the screenshot below:\n\n<img src=\"Images/Chapters/0x06h/URL_scheme.png\" width=\"100%\" />\n\nAlso in Xcode you can find this by searching for the `CFBundleURLTypes` key in the app's `Info.plist` file (example from @MASTG-APP-0028):\n\n```xml\n<key>CFBundleURLTypes</key>\n<array>\n    <dict>\n        <key>CFBundleURLName</key>\n        <string>com.iGoat.myCompany</string>\n        <key>CFBundleURLSchemes</key>\n        <array>\n            <string>iGoat</string>\n        </array>\n    </dict>\n</array>\n```\n\nIn a compiled application (or IPA), registered protocol handlers are found in the file `Info.plist` in the app bundle's root folder. Open it and search for the `CFBundleURLSchemes` key, if present, it should contain an array of strings (example from @MASTG-APP-0028):\n\n```xml\ngrep -A 5 -nri urlsch Info.plist\nInfo.plist:45:    <key>CFBundleURLSchemes</key>\nInfo.plist-46-    <array>\nInfo.plist-47-        <string>iGoat</string>\nInfo.plist-48-    </array>\n```\n\nOnce the URL scheme is registered, other apps can open the app that registered the scheme, and pass parameters by creating appropriately formatted URLs and opening them with the [`UIApplication openURL:options:completionHandler:`](https://developer.apple.com/documentation/uikit/uiapplication/1648685-openurl?language=objc \"UIApplication openURL:options:completionHandler:\") method.\n\nNote from the [App Programming Guide for iOS](https://developer.apple.com/library/archive/documentation/iPhone/Conceptual/iPhoneOSProgrammingGuide/Inter-AppCommunication/Inter-AppCommunication.html#//apple_ref/doc/uid/TP40007072-CH6-SW7 \"Registering Custom URL Schemes\"):\n\n> If more than one third-party app registers to handle the same URL scheme, there is currently no process for determining which app will be given that scheme.\n\nThis could lead to a URL scheme hijacking attack (see page 136 in [#thiel2]).\n\n### Testing Application Query Schemes Registration\n\nBefore calling the `openURL:options:completionHandler:` method, apps can call [`canOpenURL:`](https://developer.apple.com/documentation/uikit/uiapplication/1622952-canopenurl?language=objc \"UIApplication canOpenURL:\") to verify that the target app is available. However, as this method was being used by malicious app as a way to enumerate installed apps, [from iOS 9.0 the URL schemes passed to it must be also declared](https://developer.apple.com/documentation/uikit/uiapplication/1622952-canopenurl?language=objc#discussion \"Discussion about UIApplication canOpenURL:\") by adding the `LSApplicationQueriesSchemes` key to the app's `Info.plist` file and an array of up to 50 URL schemes.\n\n```xml\n<key>LSApplicationQueriesSchemes</key>\n    <array>\n        <string>url_scheme1</string>\n        <string>url_scheme2</string>\n    </array>\n```\n\n`canOpenURL` will always return `NO` for undeclared schemes, whether or not an appropriate app is installed. However, this restriction only applies to `canOpenURL`.\n\n**The `openURL:options:completionHandler:` method will still open any URL scheme, even if the `LSApplicationQueriesSchemes` array was declared**, and return `YES` / `NO` depending on the result.\n\nAs an example, Telegram declares in its [`Info.plist`](https://github.com/TelegramMessenger/Telegram-iOS/blob/master/Telegram/Telegram-iOS/Info.plist#L233 \"Telegram\\'s Info.plist Line 63\") these Queries Schemes, among others:\n\n```xml\n    <key>LSApplicationQueriesSchemes</key>\n    <array>\n        <string>dbapi-3</string>\n        <string>instagram</string>\n        <string>googledrive</string>\n        <string>comgooglemaps-x-callback</string>\n        <string>foursquare</string>\n        <string>here-location</string>\n        <string>yandexmaps</string>\n        <string>yandexnavi</string>\n        <string>comgooglemaps</string>\n        <string>youtube</string>\n        <string>twitter</string>\n        ...\n```\n\n### Testing URL Handling and Validation\n\nIn order to determine how a URL path is built and validated, if you have the original source code, you can search for the following methods:\n\n- `application:didFinishLaunchingWithOptions:` method or `application:will-FinishLaunchingWithOptions:`: verify how the decision is made and how the information about the URL is retrieved.\n- [`application:openURL:options:`](https://developer.apple.com/documentation/uikit/uiapplicationdelegate/1623112-application?language=objc \"UIApplicationDelegate application:openURL:options:\"): verify how the resource is being opened, i.e. how the data is being parsed, verify the [options](https://developer.apple.com/documentation/uikit/uiapplication/openurloptionskey \"UIApplicationOpenURLOptionsKey\"), especially if access by the calling app ([`sourceApplication`](https://developer.apple.com/documentation/uikit/uiapplication/openurloptionskey/1623128-sourceapplication \"UIApplicationOpenURLOptionsSourceApplicationKey\")) should be allowed or denied. The app might also need user permission when using the custom URL scheme.\n\nIn Telegram you will [find four different methods being used](https://github.com/peter-iakovlev/Telegram-iOS/blob/87e0a33ac438c1d702f2a0b75bf21f26866e346f/Telegram-iOS/AppDelegate.swift#L1250 \"Telegram\\'s AppDelegate.swift Line 1250\"):\n\n```default\nfunc application(_ application: UIApplication, open url: URL, sourceApplication: String?) -> Bool {\n    self.openUrl(url: url)\n    return true\n}\n\nfunc application(_ application: UIApplication, open url: URL, sourceApplication: String?,\nannotation: Any) -> Bool {\n    self.openUrl(url: url)\n    return true\n}\n\nfunc application(_ app: UIApplication, open url: URL,\noptions: [UIApplicationOpenURLOptionsKey : Any] = [:]) -> Bool {\n    self.openUrl(url: url)\n    return true\n}\n\nfunc application(_ application: UIApplication, handleOpen url: URL) -> Bool {\n    self.openUrl(url: url)\n    return true\n}\n```\n\nWe can observe some things here:\n\n- The app implements also deprecated methods like [`application:handleOpenURL:`](https://developer.apple.com/documentation/uikit/uiapplicationdelegate/1622964-application?language=objc \"UIApplicationDelegate application:handleOpenURL:\") and [`application:openURL:sourceApplication:annotation:`](https://developer.apple.com/documentation/uikit/uiapplicationdelegate/1623073-application \"UIApplicationDelegate application:openURL:sourceApplication:annotation:\").\n- The source application is not being verified in any of those methods.\n- All of them call a private `openUrl` method. You can [inspect it](https://github.com/peter-iakovlev/Telegram-iOS/blob/87e0a33ac438c1d702f2a0b75bf21f26866e346f/Telegram-iOS/AppDelegate.swift#L1270 \"Telegram\\'s AppDelegate.swift Line 1270\") to learn more about how the URL request is handled.\n\n### Testing URL Requests to Other Apps\n\nThe method [`openURL:options:completionHandler:`](https://developer.apple.com/documentation/uikit/uiapplication/1648685-openurl?language=objc \"UIApplication openURL:options:completionHandler:\") and the [deprecated `openURL:` method of `UIApplication`](https://developer.apple.com/documentation/uikit/uiapplication/1622961-openurl?language=objc \"UIApplication openURL:\") are responsible for opening URLs (i.e. to send requests / make queries to other apps) that may be local to the current app or it may be one that must be provided by a different app. If you have the original source code you can search directly for usages of those methods.\n\nAdditionally, if you are interested into knowing if the app is querying specific services or apps, and if the app is well-known, you can also search for common URL schemes online and include them in your greps. For example, a [quick Google search reveals](https://ios.gadgethacks.com/news/always-updated-list-ios-app-url-scheme-names-0184033/ \"Always-Updated List of iOS App URL Scheme Names\"):\n\n```default\nApple Music - music:// or musics:// or audio-player-event://\nCalendar - calshow:// or x-apple-calevent://\nContacts - contacts://\nDiagnostics - diagnostics:// or diags://\nGarageBand - garageband://\niBooks - ibooks:// or itms-books:// or itms-bookss://\nMail - message:// or mailto://emailaddress\nMessages - sms://phonenumber\nNotes - mobilenotes://\n...\n```\n\nWe search for this method in the Telegram source code, this time without using Xcode, just with `egrep`:\n\n```bash\n$ egrep -nr \"open.*options.*completionHandler\" ./Telegram-iOS/\n\n./AppDelegate.swift:552: return UIApplication.shared.open(parsedUrl,\n    options: [UIApplicationOpenURLOptionUniversalLinksOnly: true as NSNumber],\n    completionHandler: { value in\n./AppDelegate.swift:556: return UIApplication.shared.open(parsedUrl,\n    options: [UIApplicationOpenURLOptionUniversalLinksOnly: true as NSNumber],\n    completionHandler: { value in\n```\n\nIf we inspect the results we will see that `openURL:options:completionHandler:` is actually being used for universal links, so we have to keep searching. For example, we can search for `openURL(`:\n\n```bash\n$ egrep -nr \"openURL\\(\" ./Telegram-iOS/\n\n./ApplicationContext.swift:763:  UIApplication.shared.openURL(parsedUrl)\n./ApplicationContext.swift:792:  UIApplication.shared.openURL(URL(\n                                        string: \"https://telegram.org/deactivate?phone=\\(phone)\")!\n                                 )\n./AppDelegate.swift:423:         UIApplication.shared.openURL(url)\n./AppDelegate.swift:538:         UIApplication.shared.openURL(parsedUrl)\n...\n```\n\nIf we inspect those lines we will see how this method is also being used to open \"Settings\" or to open the \"App Store Page\".\n\nWhen just searching for `://` we see:\n\n```default\nif documentUri.hasPrefix(\"file://\"), let path = URL(string: documentUri)?.path {\nif !url.hasPrefix(\"mt-encrypted-file://?\") {\nguard let dict = TGStringUtils.argumentDictionary(inUrlString: String(url[url.index(url.startIndex,\n    offsetBy: \"mt-encrypted-file://?\".count)...])) else {\nparsedUrl = URL(string: \"https://\\(url)\")\nif let url = URL(string: \"itms-apps://itunes.apple.com/app/id\\(appStoreId)\") {\n} else if let url = url as? String, url.lowercased().hasPrefix(\"tg://\") {\n[[WKExtension sharedExtension] openSystemURL:[NSURL URLWithString:[NSString\n    stringWithFormat:@\"tel://%@\", userHandle.data]]];\n```\n\nAfter combining the results of both searches and carefully inspecting the source code we find the following piece of code:\n\n```default\nopenUrl: { url in\n            var parsedUrl = URL(string: url)\n            if let parsed = parsedUrl {\n                if parsed.scheme == nil || parsed.scheme!.isEmpty {\n                    parsedUrl = URL(string: \"https://\\(url)\")\n                }\n                if parsed.scheme == \"tg\" {\n                    return\n                }\n            }\n\n            if let parsedUrl = parsedUrl {\n                UIApplication.shared.openURL(parsedUrl)\n```\n\nBefore opening a URL, the scheme is validated, \"https\" will be added if necessary and it won't open any URL with the \"tg\" scheme. When ready it will use the deprecated `openURL` method.\n\nIf only having the compiled application (IPA) you can still try to identify which URL schemes are being used to query other apps:\n\n- Check if `LSApplicationQueriesSchemes` was declared or search for common URL schemes.\n- Also use the string `://` or build a regular expression to match URLs as the app might not be declaring some schemes.\n\nYou can do that by first verifying that the app binary contains those strings by e.g. using unix `strings` command:\n\n```bash\nstrings <yourapp> | grep \"someURLscheme://\"\n```\n\nor even better, use radare2's `iz/izz` command or rafind2, both will find strings where the unix `strings` command won't. Example from @MASTG-APP-0028:\n\n```bash\n$ r2 -qc izz~iGoat:// iGoat-Swift\n37436 0x001ee610 0x001ee610  23  24 (4.__TEXT.__cstring) ascii iGoat://?contactNumber=\n```\n\n### Testing for Deprecated Methods\n\nSearch for deprecated methods like:\n\n- [`application:handleOpenURL:`](https://developer.apple.com/documentation/uikit/uiapplicationdelegate/1622964-application?language=objc \"UIApplicationDelegate application:handleOpenURL:\")\n- [`openURL:`](https://developer.apple.com/documentation/uikit/uiapplication/1622961-openurl?language=objc \"UIApplication openURL:\")\n- [`application:openURL:sourceApplication:annotation:`](https://developer.apple.com/documentation/uikit/uiapplicationdelegate/1623073-application \"UIApplicationDelegate application:openURL:sourceApplication:annotation:\")\n\nFor example, using @MASTG-TOOL-0129 we find those three:\n\n```bash\n$ rabin2 -zzq Telegram\\ X.app/Telegram\\ X | grep -i \"openurl\"\n\n0x1000d9e90 31 30 UIApplicationOpenURLOptionsKey\n0x1000dee3f 50 49 application:openURL:sourceApplication:annotation:\n0x1000dee71 29 28 application:openURL:options:\n0x1000dee8e 27 26 application:handleOpenURL:\n0x1000df2c9 9 8 openURL:\n0x1000df766 12 11 canOpenURL:\n0x1000df772 35 34 openURL:options:completionHandler:\n...\n```"
  },
  {
    "id": "MASTG-TEST-0076",
    "title": "nothing found",
    "category": "iOS Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\nFor the static analysis we will focus mostly on the following points having `UIWebView` and `WKWebView` under scope.\n\n- Identifying WebView usage\n- Testing if JavaScript is Enabled\n- Testing for Mixed Content\n- Testing for WebView URI Manipulation\n\n### Identifying WebView Usage\n\nLook out for usages of the above mentioned WebView classes by searching in Xcode.\n\nIn the compiled binary you can search in its symbols or strings, for example using @MASTG-TOOL-0129 like this:\n\n#### UIWebView\n\n```bash\n$ rabin2 -zz ./WheresMyBrowser | egrep \"UIWebView$\"\n489 0x0002fee9 0x10002fee9   9  10 (5.__TEXT.__cstring) ascii UIWebView\n896 0x0003c813 0x0003c813  24  25 () ascii @_OBJC_CLASS_$_UIWebView\n1754 0x00059599 0x00059599  23  24 () ascii _OBJC_CLASS_$_UIWebView\n```\n\n#### WKWebView\n\n```bash\n$ rabin2 -zz ./WheresMyBrowser | egrep \"WKWebView$\"\n490 0x0002fef3 0x10002fef3   9  10 (5.__TEXT.__cstring) ascii WKWebView\n625 0x00031670 0x100031670  17  18 (5.__TEXT.__cstring) ascii unwindToWKWebView\n904 0x0003c960 0x0003c960  24  25 () ascii @_OBJC_CLASS_$_WKWebView\n1757 0x000595e4 0x000595e4  23  24 () ascii _OBJC_CLASS_$_WKWebView\n```\n\nAlternatively you can also search for known methods of these WebView classes. For example, search for the method used to initialize a WKWebView ([`init(frame:configuration:)`](https://developer.apple.com/documentation/webkit/wkwebview/1414998-init \"WKWebView init(frame:configuration:)\")):\n\n```bash\n$ rabin2 -zzq ./WheresMyBrowser | egrep \"WKWebView.*frame\"\n0x5c3ac 77 76 __T0So9WKWebViewCABSC6CGRectV5frame_So0aB13ConfigurationC13configurationtcfC\n0x5d97a 79 78 __T0So9WKWebViewCABSC6CGRectV5frame_So0aB13ConfigurationC13configurationtcfcTO\n0x6b5d5 77 76 __T0So9WKWebViewCABSC6CGRectV5frame_So0aB13ConfigurationC13configurationtcfC\n0x6c3fa 79 78 __T0So9WKWebViewCABSC6CGRectV5frame_So0aB13ConfigurationC13configurationtcfcTO\n```\n\nYou can also demangle it:\n\n```bash\n$ xcrun swift-demangle __T0So9WKWebViewCABSC6CGRectV5frame_So0aB13ConfigurationC13configurationtcfcTO\n\n---> @nonobjc __C.WKWebView.init(frame: __C_Synthesized.CGRect,\n                                configuration: __C.WKWebViewConfiguration) -> __C.WKWebView\n```\n\n### Testing if JavaScript is Enabled\n\nFirst of all, remember that JavaScript cannot be disabled for `UIWebView`s.\n\nFor `WKWebView`s, as a best practice, JavaScript should be disabled unless it is explicitly required. To verify that JavaScript was properly disabled search the project for usages of `WKPreferences` and ensure that the [`javaScriptEnabled`](https://developer.apple.com/documentation/webkit/wkpreferences/1536203-javascriptenabled \"WKPreferences javaScriptEnabled\") property is set to `false`:\n\n```default\nlet webPreferences = WKPreferences()\nwebPreferences.javaScriptEnabled = false\n```\n\nIf only having the compiled binary you can search for this in it using @MASTG-TOOL-0129:\n\n```bash\n$ rabin2 -zz ./WheresMyBrowser | grep -i \"javascriptenabled\"\n391 0x0002f2c7 0x10002f2c7  17  18 (4.__TEXT.__objc_methname) ascii javaScriptEnabled\n392 0x0002f2d9 0x10002f2d9  21  22 (4.__TEXT.__objc_methname) ascii setJavaScriptEnabled:\n```\n\nIf user scripts were defined, they will continue running as the `javaScriptEnabled` property won't affect them. See [`WKUserContentController`](https://developer.apple.com/documentation/webkit/wkusercontentcontroller \"WKUserContentController\") and [WKUserScript](https://developer.apple.com/documentation/webkit/wkuserscript \"WKUserScript\") for more information on injecting user scripts to WKWebViews.\n\n### Testing for Mixed Content\n\nIn contrast to `UIWebView`s, when using `WKWebView`s it is possible to detect [mixed content](https://developers.google.com/web/fundamentals/security/prevent-mixed-content/fixing-mixed-content?hl=en \"Preventing Mixed Content\") (HTTP content loaded from a HTTPS page). By using the method [`hasOnlySecureContent`](https://developer.apple.com/documentation/webkit/wkwebview/1415002-hasonlysecurecontent \"WKWebView hasOnlySecureContent\") it can be verified whether all resources on the page have been loaded through securely encrypted connections. This example from [#thiel2] (see page 159 and 160) uses this to ensure that only content loaded via HTTPS is shown to the user, otherwise an alert is displayed telling the user that mixed content was detected.\n\nIn the compiled binary you can use @MASTG-TOOL-0129:\n\n```bash\n$ rabin2 -zz ./WheresMyBrowser | grep -i \"hasonlysecurecontent\"\n\n# nothing found\n```\n\nIn this case, the app does not make use of this.\n\nIn addition, if you have the original source code or the IPA, you can inspect the embedded HTML files and verify that they do not include mixed content. Search for `http://` in the source and inside tag attributes, but remember that this might give false positives as, for example, finding an anchor tag `<a>` that includes a `http://` inside its `href` attribute does not always present a mixed content issue. Learn more about mixed content in the [MDN Web Docs](https://developer.mozilla.org/en-US/docs/Web/Security/Mixed_content \"Mixed Content\").\n\n### Testing for WebView URI Manipulation\n\nMake sure that the WebView's URI cannot be manipulated by the user in order to load other types of resources than necessary for the functioning of the WebView. This can be specifically dangerous when the WebView's content is loaded from the local file system, allowing the user to navigate to other resources within the application."
  },
  {
    "id": "MASTG-TEST-0077",
    "title": "Mobile Security Test 0077",
    "category": "iOS Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\n- Testing How WebViews Load Content\n- Testing WebView file access\n- Checking telephone number detection\n\n### Testing How WebViews Load Content\n\nIf a WebView is loading content from the app data directory, users should not be able to change the filename or path from which the file is loaded, and they shouldn't be able to edit the loaded file.\n\nThis presents an issue especially in `UIWebView`s loading untrusted content via the deprecated methods [`loadHTMLString:baseURL:`](https://developer.apple.com/documentation/uikit/uiwebview/1617979-loadhtmlstring?language=objc \"UIWebView loadHTMLString:baseURL:\") or [`loadData:MIMEType:textEncodingName:baseURL:`](https://developer.apple.com/documentation/uikit/uiwebview/1617941-loaddata?language=objc \"UIWebView loadData:MIMEType:textEncodingName:baseURL:\") and setting the `baseURL` parameter to `nil` or to a `file:` or `applewebdata:` URL schemes. In this case, in order to prevent unauthorized access to local files, the best option is to set it instead to `about:blank`. However, the recommendation is to avoid the use of `UIWebView`s and switch to `WKWebView`s instead.\n\nHere's an example of a vulnerable `UIWebView` from [\"Where's My Browser?\"](https://github.com/authenticationfailure/WheresMyBrowser.iOS/blob/master/WheresMyBrowser/UIWebViewController.swift#L219 \"Where\\'s My Browser? UIWebViewController.swift Line 219\"):\n\n```default\nlet scenario2HtmlPath = Bundle.main.url(forResource: \"web/UIWebView/scenario2.html\", withExtension: nil)\ndo {\n    let scenario2Html = try String(contentsOf: scenario2HtmlPath!, encoding: .utf8)\n    uiWebView.loadHTMLString(scenario2Html, baseURL: nil)\n} catch {}\n```\n\nThe page loads resources from the internet using HTTP, enabling a potential MITM to exfiltrate secrets contained in local files, e.g. in shared preferences.\n\nWhen working with `WKWebView`s, Apple recommends using [`loadHTMLString:baseURL:`](https://developer.apple.com/documentation/webkit/wkwebview/1415004-loadhtmlstring?language=objc \"WKWebView loadHTMLString:baseURL:\") or [`loadData:MIMEType:textEncodingName:baseURL:`](https://developer.apple.com/documentation/webkit/wkwebview/1415011-loaddata?language=objc \"WKWebView loadData:MIMEType:textEncodingName:baseURL:\") to load local HTML files and `loadRequest:` for web content. Typically, the local files are loaded in combination with methods including, among others: [`pathForResource:ofType:`](https://developer.apple.com/documentation/foundation/nsbundle/1410989-pathforresource \"NSBundle pathForResource:ofType:\"), [`URLForResource:withExtension:`](https://developer.apple.com/documentation/foundation/nsbundle/1411540-urlforresource?language=objc \"NSBundle URLForResource:withExtension:\") or [`init(contentsOf:encoding:)`](https://developer.apple.com/documentation/swift/string/3126736-init \"String init(contentsOf:encoding:)\").\n\nSearch the source code for the mentioned methods and inspect their parameters.\n\nExample in Objective-C:\n\n```objectivec\n\n- (void)viewDidLoad\n{\n    [super viewDidLoad];\n    WKWebViewConfiguration *configuration = [[WKWebViewConfiguration alloc] init];\n\n    self.webView = [[WKWebView alloc] initWithFrame:CGRectMake(10, 20,\n        CGRectGetWidth([UIScreen mainScreen].bounds) - 20,\n        CGRectGetHeight([UIScreen mainScreen].bounds) - 84) configuration:configuration];\n    self.webView.navigationDelegate = self;\n    [self.view addSubview:self.webView];\n\n    NSString *filePath = [[NSBundle mainBundle] pathForResource:@\"example_file\" ofType:@\"html\"];\n    NSString *html = [NSString stringWithContentsOfFile:filePath\n                                encoding:NSUTF8StringEncoding error:nil];\n    [self.webView loadHTMLString:html baseURL:[NSBundle mainBundle].resourceURL];\n}\n\n```\n\nExample in Swift from [\"Where's My Browser?\"](https://github.com/authenticationfailure/WheresMyBrowser.iOS/blob/master/WheresMyBrowser/WKWebViewController.swift#L196 \"Where\\'s My Browser? WKWebViewController.swift Line 196\"):\n\n```default\nlet scenario2HtmlPath = Bundle.main.url(forResource: \"web/WKWebView/scenario2.html\", withExtension: nil)\ndo {\n    let scenario2Html = try String(contentsOf: scenario2HtmlPath!, encoding: .utf8)\n    wkWebView.loadHTMLString(scenario2Html, baseURL: nil)\n} catch {}\n```\n\nIf only having the compiled binary, you can also search for these methods using @MASTG-TOOL-0129:\n\n```bash\n$ rabin2 -zz ./WheresMyBrowser | grep -i \"loadHTMLString\"\n231 0x0002df6c 24 (4.__TEXT.__objc_methname) ascii loadHTMLString:baseURL:\n```\n\nIn a case like this, it is recommended to perform dynamic analysis to ensure that this is in fact being used and from which kind of WebView. The `baseURL` parameter here doesn't present an issue as it will be set to \"null\" but could be an issue if not set properly when using a `UIWebView`. See \"Checking How WebViews are Loaded\" for an example about this.\n\nIn addition, you should also verify if the app is using the method [`loadFileURL: allowingReadAccessToURL:`](https://developer.apple.com/documentation/webkit/wkwebview/1414973-loadfileurl?language=objc \"WKWebView loadFileURL:allowingReadAccessToURL:\"). Its first parameter is `URL` and contains the URL to be loaded in the WebView, its second parameter `allowingReadAccessToURL` may contain a single file or a directory. If containing a single file, that file will be available to the WebView. However, if it contains a directory, all files on that directory will be made available to the WebView. Therefore, it is worth inspecting this and in case it is a directory, verifying that no sensitive data can be found inside it.\n\nExample in Swift from [\"Where's My Browser?\"](https://github.com/authenticationfailure/WheresMyBrowser.iOS/blob/master/WheresMyBrowser/WKWebViewController.swift#L186 \"Where\\'s My Browser? WKWebViewController.swift Line 186\"):\n\n```default\nvar scenario1Url = FileManager.default.urls(for: .libraryDirectory, in: .userDomainMask)[0]\nscenario1Url = scenario1Url.appendingPathComponent(\"WKWebView/scenario1.html\")\nwkWebView.loadFileURL(scenario1Url, allowingReadAccessTo: scenario1Url)\n```\n\nIn this case, the parameter `allowingReadAccessToURL` contains a single file \"WKWebView/scenario1.html\", meaning that the WebView has exclusively access to that file.\n\nIn the compiled binary you can use @MASTG-TOOL-0129:\n\n```bash\n$ rabin2 -zz ./WheresMyBrowser | grep -i \"loadFileURL\"\n237 0x0002dff1 37 (4.__TEXT.__objc_methname) ascii loadFileURL:allowingReadAccessToURL:\n```\n\n### Testing WebView File Access\n\nIf you have found a `UIWebView` being used, then the following applies:\n\n- The `file://` scheme is always enabled.\n- File access from `file://` URLs is always enabled.\n- Universal access from `file://` URLs is always enabled.\n\nRegarding `WKWebView`s:\n\n- The `file://` scheme is also always enabled and it **cannot be disabled**.\n- It disables file access from `file://` URLs by default but it can be enabled.\n\nThe following WebView properties can be used to configure file access:\n\n- `allowFileAccessFromFileURLs` (`WKPreferences`, `false` by default): it enables JavaScript running in the context of a `file://` scheme URL to access content from other `file://` scheme URLs.\n- `allowUniversalAccessFromFileURLs` (`WKWebViewConfiguration`, `false` by default): it enables JavaScript running in the context of a `file://` scheme URL to access content from any origin.\n\nFor example, it is possible to set the **[undocumented property](https://github.com/WebKit/webkit/blob/master/Source/WebKit/UIProcess/API/Cocoa/WKPreferences.mm#L470 \"WebKit WKPreferences.mm Line 470\")** `allowFileAccessFromFileURLs` by doing this:\n\nObjective-C:\n\n```objectivec\n\n[webView.configuration.preferences setValue:@YES forKey:@\"allowFileAccessFromFileURLs\"];\n\n```\n\nSwift:\n\n```default\n\nwebView.configuration.preferences.setValue(true, forKey: \"allowFileAccessFromFileURLs\")\n\n```\n\nIf one or more of the above properties are activated, you should determine whether they are really necessary for the app to work properly.\n\n### Checking Telephone Number Detection\n\nIn Safari on iOS, telephone number detection is on by default. However, you might want to turn it off if your HTML page contains numbers that can be interpreted as phone numbers, but are not phone numbers, or to prevent the DOM document from being modified when parsed by the browser. To turn off telephone number detection in Safari on iOS, use the format-detection meta tag (`<meta name = \"format-detection\" content = \"telephone=no\">`). An example of this can be found in the [Apple developer documentation](https://developer.apple.com/library/archive/featuredarticles/iPhoneURLScheme_Reference/PhoneLinks/PhoneLinks.html#//apple_ref/doc/uid/TP40007899-CH6-SW2 \"Phone Links: Turning telephone number detection off\"). Phone links should be then used (e.g. `<a href=\"tel:1-408-555-5555\">1-408-555-5555</a>`) to explicitly create a link."
  },
  {
    "id": "MASTG-TEST-0078",
    "title": "Mobile Security Test 0078",
    "category": "iOS Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\n### Testing UIWebView JavaScript to Native Bridges\n\nSearch for code that maps native objects to the `JSContext` associated with a WebView and analyze what functionality it exposes, for example no sensitive data should be accessible and exposed to WebViews.\n\nIn Objective-C, the `JSContext` associated with a `UIWebView` is obtained as follows:\n\n```objectivec\n\n[webView valueForKeyPath:@\"documentView.webView.mainFrame.javaScriptContext\"]\n\n```\n\n### Testing WKWebView JavaScript to Native Bridges\n\nVerify if a JavaScript to native bridge exists by searching for `WKScriptMessageHandler` and check all exposed methods. Then verify how the methods are called.\n\nThe following example from [\"Where's My Browser?\"](https://github.com/authenticationfailure/WheresMyBrowser.iOS/blob/b8d4abda4000aa509c7a5de79e5c90360d1d0849/WheresMyBrowser/WKWebViewPreferencesManager.swift#L98 \"Where\\'s My Browser? WKWebViewPreferencesManager.swift Line 98\") demonstrates this.\n\nFirst we see how the JavaScript bridge is enabled:\n\n```swift\nfunc enableJavaScriptBridge(_ enabled: Bool) {\n    options_dict[\"javaScriptBridge\"]?.value = enabled\n    let userContentController = wkWebViewConfiguration.userContentController\n    userContentController.removeScriptMessageHandler(forName: \"javaScriptBridge\")\n\n    if enabled {\n            let javaScriptBridgeMessageHandler = JavaScriptBridgeMessageHandler()\n            userContentController.add(javaScriptBridgeMessageHandler, name: \"javaScriptBridge\")\n    }\n}\n```\n\nAdding a script message handler with name `\"name\"` (or `\"javaScriptBridge\"` in the example above) causes the JavaScript function `window.webkit.messageHandlers.myJavaScriptMessageHandler.postMessage` to be defined in all frames in all web views that use the user content controller. It can be then [used from the HTML file like this](https://github.com/authenticationfailure/WheresMyBrowser.iOS/blob/d4e2d9efbde8841bf7e4a8800418dda6bb116ec6/WheresMyBrowser/web/WKWebView/scenario3.html#L33 \"Where\\'s My Browser? WKWebView/scenario3.html Line 33\"):\n\n```javascript\nfunction invokeNativeOperation() {\n    value1 = document.getElementById(\"value1\").value\n    value2 = document.getElementById(\"value2\").value\n    window.webkit.messageHandlers.javaScriptBridge.postMessage([\"multiplyNumbers\", value1, value2]);\n}\n```\n\nThe called function resides in [`JavaScriptBridgeMessageHandler.swift`](https://github.com/authenticationfailure/WheresMyBrowser.iOS/blob/b8d4abda4000aa509c7a5de79e5c90360d1d0849/WheresMyBrowser/JavaScriptBridgeMessageHandler.swift#L29 \"Where\\'s My Browser? JavaScriptBridgeMessageHandler.swift Line 29\"):\n\n```swift\nclass JavaScriptBridgeMessageHandler: NSObject, WKScriptMessageHandler {\n\n//...\n\ncase \"multiplyNumbers\":\n\n        let arg1 = Double(messageArray[1])!\n        let arg2 = Double(messageArray[2])!\n        result = String(arg1 * arg2)\n//...\n\nlet javaScriptCallBack = \"javascriptBridgeCallBack('\\(functionFromJS)','\\(result)')\"\nmessage.webView?.evaluateJavaScript(javaScriptCallBack, completionHandler: nil)\n```\n\nThe problem here is that the `JavaScriptBridgeMessageHandler` not only contains that function, it also exposes a sensitive function:\n\n```swift\ncase \"getSecret\":\n        result = \"XSRSOGKC342\"\n```"
  },
  {
    "id": "MASTG-TEST-0081",
    "title": "Mobile Security Test 0081",
    "category": "iOS Security Testing",
    "description": "Mobile application security test as per OWASP MASTG guidelines.",
    "full_description": "Mobile application security test as per OWASP MASTG guidelines."
  },
  {
    "id": "MASTG-TEST-0082",
    "title": "Mobile Security Test 0082",
    "category": "iOS Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\nExtract the entitlements from the app (@MASTG-TECH-0111) and check the value of the `get-task-allow` key. If it is set to `true`, the app is debuggable.\n\n```bash\n$ ldid -e iGoat-Swift.app/iGoat-Swift\n```\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\">\n<plist version=\"1.0\">\n<dict>\n    <key>application-identifier</key>\n    <string>TNAJ496RHB.OWASP.iGoat-Swift</string>\n    <key>com.apple.developer.team-identifier</key>\n    <string>TNAJ496RHB</string>\n    <key>get-task-allow</key>\n    <true/>\n    <key>keychain-access-groups</key>\n    <array>\n        <string>TNAJ496RHB.OWASP.iGoat-Swift</string>\n    </array>\n</dict>\n</plist>\n```"
  },
  {
    "id": "MASTG-TEST-0083",
    "title": "Mobile Security Test 0083",
    "category": "iOS Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\nTo verify the existence of debug symbols you can use objdump from [binutils](https://www.gnu.org/s/binutils/ \"Binutils\") or [llvm-objdump](https://llvm.org/docs/CommandGuide/llvm-objdump.html \"llvm-objdump\") to inspect all of the app binaries.\n\nIn the following snippet we run objdump over `TargetApp` (the iOS main app executable) to show the typical output of a binary containing debug symbols which are marked with the `d` (debug) flag. Check the [objdump man page](https://www.unix.com/man-page/osx/1/objdump/ \"objdump man page\") for information about various other symbol flag characters.\n\n```bash\n$ objdump --syms TargetApp\n\n0000000100007dc8 l    d  *UND* -[ViewController handleSubmitButton:]\n000000010000809c l    d  *UND* -[ViewController touchesBegan:withEvent:]\n0000000100008158 l    d  *UND* -[ViewController viewDidLoad]\n...\n000000010000916c l    d  *UND* _disable_gdb\n00000001000091d8 l    d  *UND* _detect_injected_dylds\n00000001000092a4 l    d  *UND* _isDebugged\n...\n```\n\nTo prevent the inclusion of debug symbols, set `Strip Debug Symbols During Copy` to `YES` via the XCode project's build settings. Stripping debugging symbols will not only reduce the size of the binary but also increase the difficulty of reverse engineering."
  },
  {
    "id": "MASTG-TEST-0084",
    "title": "Mobile Security Test 0084",
    "category": "iOS Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\nYou can take the following static analysis approach for the logging statements:\n\n1. Import the application's code into Xcode.\n2. Search the code for the following printing functions: `NSLog`, `println`, `print`, `dump`, `debugPrint`.\n3. When you find one of them, determine whether the developers used a wrapping function around the logging function for better mark up of the statements to be logged; if so, add that function to your search.\n4. For every result of steps 2 and 3, determine whether macros or debug-state related guards have been set to turn the logging off in the release build. Please note the change in how Objective-C can use preprocessor macros:\n\n```objectivec\n#ifdef DEBUG\n    // Debug-only code\n#endif\n```\n\nThe procedure for enabling this behavior in Swift has changed: you need to either set environment variables in your scheme or set them as custom flags in the target's build settings. Please note that the following functions (which allow you to determine whether the app was built in the Swift 2.1. release-configuration) aren't recommended, as Xcode 8 and Swift 3 don't support these functions:\n\n- `_isDebugAssertConfiguration`\n- `_isReleaseAssertConfiguration`\n- `_isFastAssertConfiguration`.\n\nDepending on the application's setup, there may be more logging functions. For example, when [CocoaLumberjack](https://github.com/CocoaLumberjack/CocoaLumberjack \"CocoaLumberjack\") is used, static analysis is a bit different.\n\nFor the \"debug-management\" code (which is built-in): inspect the storyboards to see whether there are any flows and/or view-controllers that provide functionality different from the functionality the application should support. This functionality can be anything from debug views to printed error messages, from custom stub-response configurations to logs written to files on the application's file system or a remote server.\n\nAs a developer, incorporating debug statements into your application's debug version should not be a problem as long as you make sure that the debug statements are never present in the application's release version.\n\nIn Objective-C, developers can use preprocessor macros to filter out debug code:\n\n```objectivec\n#ifdef DEBUG\n    // Debug-only code\n#endif\n```\n\nIn Swift 2 (with Xcode 7), you have to set custom compiler flags for every target, and compiler flags have to start with \"-D\". So you can use the following annotations when the debug flag `DMSTG-DEBUG` is set:\n\n```objectivec\n#if MSTG_DEBUG\n    // Debug-only code\n#endif\n```\n\nIn Swift 3 (with Xcode 8), you can set Active Compilation Conditions in Build settings/Swift compiler - Custom flags. Instead of a preprocessor, Swift 3 uses [conditional compilation blocks](https://developer.apple.com/library/content/documentation/Swift/Conceptual/BuildingCocoaApps/InteractingWithCAPIs.html#//apple_ref/doc/uid/TP40014216-CH8-ID34 \"Swift conditional compilation blocks\") based on the defined conditions:\n\n```objectivec\n#if DEBUG_LOGGING\n    // Debug-only code\n#endif\n```"
  },
  {
    "id": "MASTG-TEST-0088",
    "title": "Mobile Security Test 0088",
    "category": "iOS Security Testing",
    "description": "To test for jailbreak detection install the app on a jailbroken device.",
    "full_description": "To test for jailbreak detection install the app on a jailbroken device.\n\n**Launch the app and see what happens:**\n\nIf it implements jailbreak detection, you might notice one of the following things:\n\n- The app crashes and closes immediately, without any notification.\n- A pop-up window indicates that the app won't run on a jailbroken device.\n\nNote that crashes might be an indicator of jailbreak detection but the app may be crashing for any other reasons, e.g. it may have a bug. We recommend to test the app on non-jailbroken device first, especially when you're testing preproduction versions.\n\n**Launch the app and try to bypass Jailbreak Detection using an automated tool:**\n\nIf it implements jailbreak detection, you might be able to see indicators of that in the output of the tool. See section [\"Automated Jailbreak Detection Bypass\"](../../../Document/0x06j-Testing-Resiliency-Against-Reverse-Engineering.md#automated-jailbreak-detection-bypass).\n\n**Reverse Engineer the app:**\n\nThe app might be using techniques that are not implemented in the automated tools that you've used. If that's the case you must reverse engineer the app to find proofs. See section [\"Manual Jailbreak Detection Bypass\"](../../../Document/0x06j-Testing-Resiliency-Against-Reverse-Engineering.md#manual-jailbreak-detection-bypass)."
  },
  {
    "id": "MASTG-TEST-0089",
    "title": "Mobile Security Test 0089",
    "category": "iOS Security Testing",
    "description": "In order to test for anti-debugging detection you can try to attach a debugger to the app and see what happens.",
    "full_description": "In order to test for anti-debugging detection you can try to attach a debugger to the app and see what happens.\n\nThe app should respond in some way. For example by:\n\n- Alerting the user and asking for accepting liability.\n- Preventing execution by gracefully terminating.\n- Securely wiping any sensitive data stored on the device.\n- Reporting to a backend server, e.g, for fraud detection.\n\nTry to hook or reverse engineer the app using the methods from section [\"Anti-Debugging Detection\"](../../../Document/0x05j-Testing-Resiliency-Against-Reverse-Engineering.md#anti-debugging).\n\nNext, work on bypassing the detection and answer the following questions:\n\n- Can the mechanisms be bypassed trivially (e.g., by hooking a single API function)?\n- How difficult is identifying the detection code via static and dynamic analysis?\n- Did you need to write custom code to disable the defenses? How much time did you need?\n- What is your assessment of the difficulty of bypassing the mechanisms?"
  },
  {
    "id": "MASTG-TEST-0090",
    "title": "Mobile Security Test 0090",
    "category": "iOS Security Testing",
    "description": "**Application Source Code Integrity Checks:**",
    "full_description": "**Application Source Code Integrity Checks:**\n\nRun the app on the device in an unmodified state and make sure that everything works. Then apply some patches to the executable (e.g. see @MASTG-TECH-0090), re-sign the app (@MASTG-TECH-0092), and run it.\n\nThe app should respond in some way. For example by:\n\n- Alerting the user and asking for accepting liability.\n- Preventing execution by gracefully terminating.\n- Securely wiping any sensitive data stored on the device.\n- Reporting to a backend server, e.g, for fraud detection.\n\nWork on bypassing the defenses and answer the following questions:\n\n- Can the mechanisms be bypassed trivially (e.g., by hooking a single API function)?\n- How difficult is identifying the detection code via static and dynamic analysis?\n- Did you need to write custom code to disable the defenses? How much time did you need?\n- What is your assessment of the difficulty of bypassing the mechanisms?\n\n**File Storage Integrity Checks:**\n\nGo to the app data directories as indicated in @MASTG-TECH-0059 and modify some files.\n\nNext, work on bypassing the defenses and answer the following questions:\n\n- Can the mechanisms be bypassed trivially (e.g., by changing the contents of a file or a key-value pair)?\n- How difficult is obtaining the HMAC key or the asymmetric private key?\n- Did you need to write custom code to disable the defenses? How much time did you need?\n- What is your assessment of the difficulty of bypassing the mechanisms?"
  },
  {
    "id": "MASTG-TEST-0091",
    "title": "Mobile Security Test 0091",
    "category": "iOS Security Testing",
    "description": "Launch the app with various reverse engineering tools and frameworks installed on your test device, such as @MASTG-TOOL-0031, @MASTG-TOOL-0139, or @MASTG-TOOL-0066.",
    "full_description": "Launch the app with various reverse engineering tools and frameworks installed on your test device, such as @MASTG-TOOL-0031, @MASTG-TOOL-0139, or @MASTG-TOOL-0066.\n\nThe app should respond in some way to the presence of those tools. For example by:\n\n- Alerting the user and asking for accepting liability.\n- Preventing execution by gracefully terminating.\n- Securely wiping any sensitive data stored on the device.\n- Reporting to a backend server, e.g, for fraud detection.\n\nNext, work on bypassing the detection of the reverse engineering tools and answer the following questions:\n\n- Can the mechanisms be bypassed trivially (e.g., by hooking a single API function)?\n- How difficult is identifying the detection code via static and dynamic analysis?\n- Did you need to write custom code to disable the defenses? How much time did you need?\n- What is your assessment of the difficulty of bypassing the mechanisms?"
  },
  {
    "id": "MASTG-TEST-0092",
    "title": "Mobile Security Test 0092",
    "category": "iOS Security Testing",
    "description": "In order to test for emulator detection you can try to run the app on different emulators as indicated in section [\"Emulator Detection\"](../../../Document/0x06j-Testing-Resiliency-Against-Reverse-Engi...",
    "full_description": "In order to test for emulator detection you can try to run the app on different emulators as indicated in section [\"Emulator Detection\"](../../../Document/0x06j-Testing-Resiliency-Against-Reverse-Engineering.md#emulator-detection) and see what happens.\n\nThe app should respond in some way. For example by:\n\n- Alerting the user and asking for accepting liability.\n- Preventing execution by gracefully terminating.\n- Reporting to a backend server, e.g, for fraud detection.\n\nYou can also reverse engineer the app using ideas for strings and methods from section [\"Emulator Detection\"](../../../Document/0x06j-Testing-Resiliency-Against-Reverse-Engineering.md#emulator-detection).\n\nNext, work on bypassing this detection and answer the following questions:\n\n- Can the mechanisms be bypassed trivially (e.g., by hooking a single API function)?\n- How difficult is identifying the detection code via static and dynamic analysis?\n- Did you need to write custom code to disable the defenses? How much time did you need?\n- What is your assessment of the difficulty of bypassing the mechanisms?"
  },
  {
    "id": "MASTG-TEST-0093",
    "title": "Mobile Security Test 0093",
    "category": "iOS Security Testing",
    "description": "Attempt to disassemble the Mach-O in the IPA and any included library files in the \"Frameworks\" directory (.dylib or .framework files), and perform static analysis. At the very least, the app's core f...",
    "full_description": "Attempt to disassemble the Mach-O in the IPA and any included library files in the \"Frameworks\" directory (.dylib or .framework files), and perform static analysis. At the very least, the app's core functionality (i.e., the functionality meant to be obfuscated) shouldn't be easily discerned. Verify that:\n\n- meaningful identifiers, such as class names, method names, and variable names, have been discarded.\n- string resources and strings in binaries are encrypted.\n- code and data related to the protected functionality is encrypted, packed, or otherwise concealed.\n\nFor a more detailed assessment, you need a detailed understanding of the relevant threats and the obfuscation methods used."
  },
  {
    "id": "MASTG-TEST-0052",
    "title": "Mobile Security Test 0052",
    "category": "iOS Security Testing",
    "description": "This test case focuses on identifying potentially sensitive data stored by an application and verifying if it is securely stored. The following checks should be performed:",
    "full_description": "This test case focuses on identifying potentially sensitive data stored by an application and verifying if it is securely stored. The following checks should be performed:\n\n- Analyze data storage in the source code.\n- Be sure to trigger all possible functionality in the application (e.g. by clicking everywhere possible) in order to ensure data generation.\n- Check all application generated and modified files and ensure that the storage method is sufficiently secure.\n    - This includes `NSUserDefaults`, databases, KeyChain, Internal Storage, External Storage, etc.\n\n**NOTE:** For MASVS L1 compliance, it is sufficient to store data unencrypted in the application's internal storage directory (sandbox). For L2 compliance, additional encryption is required using cryptographic keys securely managed in the iOS KeyChain. This includes using envelope encryption (DEK+KEK) or equivalent methods."
  },
  {
    "id": "MASTG-TEST-0053",
    "title": "define NSLog (...) NSLog(__VA_ARGS__)",
    "category": "iOS Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\nUse the following keywords to check the app's source code for predefined and custom logging statements:\n\n- For predefined and built-in functions:\n    - NSLog\n    - NSAssert\n    - NSCAssert\n    - fprintf\n- For custom functions:\n    - Logging\n    - Logfile\n\nA generalized approach to this issue is to use a define to enable `NSLog` statements for development and debugging, then disable them before shipping the software. You can do this by adding the following code to the appropriate PREFIX_HEADER (\\*.pch) file:\n\n```objectivec\n#ifdef DEBUG\n#   define NSLog (...) NSLog(__VA_ARGS__)\n#else\n#   define NSLog (...)\n#endif\n```"
  },
  {
    "id": "MASTG-TEST-0054",
    "title": "Mobile Security Test 0054",
    "category": "iOS Security Testing",
    "description": "Sensitive information might be leaked to third parties by several means. On iOS typically via third-party services embedded in the app.",
    "full_description": "Sensitive information might be leaked to third parties by several means. On iOS typically via third-party services embedded in the app.\n\nThe features these services provide can involve tracking services to monitor the user's behavior while using the app, selling banner advertisements, or improving the user experience.\n\nThe downside is that developers don't usually know the details of the code executed via third-party libraries. Consequently, no more information than is necessary should be sent to a service, and no sensitive information should be disclosed.\n\nMost third-party services are implemented in two ways:\n\n- with a standalone library\n- with a full SDK"
  },
  {
    "id": "MASTG-TEST-0055",
    "title": "Mobile Security Test 0055",
    "category": "iOS Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\n- Search through the source code for similar implementations, such as\n\n```objectivec\n  textObject.autocorrectionType = UITextAutocorrectionTypeNo;\n  textObject.secureTextEntry = YES;\n```\n\n- Open xib and storyboard files in the `Interface Builder` of Xcode and verify the states of `Secure Text Entry` and `Correction` in the `Attributes Inspector` for the appropriate object.\n\nThe application must prevent the caching of sensitive information entered into text fields. You can prevent caching by disabling it programmatically, using the `textObject.autocorrectionType = UITextAutocorrectionTypeNo` directive in the desired UITextFields, UITextViews, and UISearchBars. For data that should be masked, such as PINs and passwords, set `textObject.secureTextEntry` to `YES`.\n\n```objectivec\nUITextField *textField = [ [ UITextField alloc ] initWithFrame: frame ];\ntextField.autocorrectionType = UITextAutocorrectionTypeNo;\n```"
  },
  {
    "id": "MASTG-TEST-0058",
    "title": "Mobile Security Test 0058",
    "category": "iOS Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\nA backup of a device on which a mobile application has been installed will include all subdirectories (except for `Library/Caches/`) and files in the [app's private directory](https://developer.apple.com/library/content/documentation/FileManagement/Conceptual/FileSystemProgrammingGuide/FileSystemOverview/FileSystemOverview.html#//apple_ref/doc/uid/TP40010672-CH2-SW12 \"Directories of an iOS App\").\n\nTherefore, avoid storing sensitive data in plaintext within any of the files or folders that are in the app's private directory or subdirectories.\n\nAlthough all the files in `Documents/` and `Library/Application Support/` are always backed up by default, you can [exclude files from the backup](https://developer.apple.com/library/content/documentation/FileManagement/Conceptual/FileSystemProgrammingGuide/FileSystemOverview/FileSystemOverview.html#//apple_ref/doc/uid/TP40010672-CH2-SW28 \"Where You Should Put Your App\\'s Files\") by calling `NSURL setResourceValue:forKey:error:` with the `NSURLIsExcludedFromBackupKey` key.\n\nYou can use the [NSURLIsExcludedFromBackupKey](https://developer.apple.com/reference/foundation/nsurl#//apple_ref/c/data/NSURLIsExcludedFromBackupKey \"NSURLIsExcludedFromBackupKey\") and [CFURLIsExcludedFromBackupKey](https://developer.apple.com/reference/corefoundation/cfurl-rd7#//apple_ref/c/data/kCFURLIsExcludedFromBackupKey \"kCFURLIsExcludedFromBackupKey\") file system properties to exclude files and directories from backups. An app that needs to exclude many files can do so by creating its own subdirectory and marking that directory excluded. Apps should create their own directories for exclusion instead of excluding system-defined directories.\n\nBoth file system properties are preferable to the deprecated approach of directly setting an extended attribute. All apps running on iOS version 5.1 and later should use these properties to exclude data from backups.\n\nThe following is [sample Objective-C code for excluding a file from a backup](https://developer.apple.com/library/content/qa/qa1719/index.html \"How do I prevent files from being backed up to iCloud and iTunes?\") on iOS 5.1 and later:\n\n```objectivec\n- (BOOL)addSkipBackupAttributeToItemAtPath:(NSString *) filePathString\n{\n    NSURL* URL= [NSURL fileURLWithPath: filePathString];\n    assert([[NSFileManager defaultManager] fileExistsAtPath: [URL path]]);\n\n    NSError *error = nil;\n    BOOL success = [URL setResourceValue: [NSNumber numberWithBool: YES]\n                                  forKey: NSURLIsExcludedFromBackupKey error: &error];\n    if(!success){\n        NSLog(@\"Error excluding %@ from backup %@\", [URL lastPathComponent], error);\n    }\n    return success;\n}\n```\n\nThe following is sample Swift code for excluding a file from a backup on iOS 5.1 and later, see [Swift excluding files from iCloud backup](https://bencoding.com/2017/02/20/swift-excluding-files-from-icloud-backup/) for more information:\n\n```swift\nenum ExcludeFileError: Error {\n    case fileDoesNotExist\n    case error(String)\n}\n\nfunc excludeFileFromBackup(filePath: URL) -> Result<Bool, ExcludeFileError> {\n    var file = filePath\n\n    do {\n        if FileManager.default.fileExists(atPath: file.path) {\n            var res = URLResourceValues()\n            res.isExcludedFromBackup = true\n            try file.setResourceValues(res)\n            return .success(true)\n\n        } else {\n            return .failure(.fileDoesNotExist)\n        }\n    } catch {\n        return .failure(.error(\"Error excluding \\(file.lastPathComponent) from backup \\(error)\"))\n    }\n}\n```"
  },
  {
    "id": "MASTG-TEST-0060",
    "title": "using strings",
    "category": "iOS Security Testing",
    "description": "## Static Analysis",
    "full_description": "## Static Analysis\n\nWhen performing static analysis for sensitive data exposed via memory, you should\n\n- try to identify application components and map where the data is used,\n- make sure that sensitive data is handled with as few components as possible,\n- make sure that object references are properly removed once the object containing sensitive data is no longer needed,\n- make sure that highly sensitive data is overwritten as soon as it is no longer needed,\n- not pass such data via immutable data types, such as `String` and `NSString`,\n- avoid non-primitive data types (because they might leave data behind),\n- overwrite the value in memory before removing references,\n- pay attention to third-party components (libraries and frameworks). Having a public API that handles data according to the recommendations above is a good indicator that developers considered the issues discussed here."
  }
]